#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç³»ç»ŸåŠŸèƒ½æµ‹è¯•è„šæœ¬
éªŒè¯æ‰€æœ‰ç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import numpy as np
import os
import sys
from datetime import datetime

def test_enhanced_gru():
    """æµ‹è¯•å¢å¼ºGRUæ¨¡å‹"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºGRUæ¨¡å‹...")
    
    try:
        from models.enhanced_gru import create_enhanced_model
        
        # åˆ›å»ºæµ‹è¯•å‚æ•°
        class Args:
            def __init__(self):
                self.hidden_layer = 128
                self.out_class = 4
                self.dia_layers = 2
                self.dropout = 0.3
                self.attention = True
                self.speaker_norm = True
                self.speaker_adversarial = True
                self.freeze_layers = 6
        
        args = Args()
        model = create_enhanced_model(args)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size, seq_len, feature_dim = 4, 100, 768
        dummy_input = torch.randn(batch_size, seq_len, feature_dim)
        
        outputs = model.utterance_net(dummy_input)
        
        assert outputs['emotion_logits'].shape == (batch_size, 4), f"æƒ…æ„Ÿè¾“å‡ºå½¢çŠ¶é”™è¯¯: {outputs['emotion_logits'].shape}"
        assert outputs['speaker_logits'].shape == (batch_size, 10), f"è¯´è¯äººè¾“å‡ºå½¢çŠ¶é”™è¯¯: {outputs['speaker_logits'].shape}"
        
        print("âœ… å¢å¼ºGRUæ¨¡å‹æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ å¢å¼ºGRUæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_speaker_independent_data():
    """æµ‹è¯•è¯´è¯äººæ— å…³æ•°æ®å¤„ç†"""
    print("ğŸ§ª æµ‹è¯•è¯´è¯äººæ— å…³æ•°æ®å¤„ç†...")
    
    try:
        from utils.speaker_independent_data import SpeakerIndependentDataLoader
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        mock_data = []
        speakers = ['Ses01F', 'Ses01M', 'Ses02F', 'Ses02M']
        emotions = [0, 1, 2, 3]
        
        for i in range(100):
            sample = {
                'id': f'{speakers[i % len(speakers)]}_test_{i:03d}',
                'emotion': emotions[i % len(emotions)],
                'wav_encodings': torch.randn(50, 768),
                'speaker': speakers[i % len(speakers)]
            }
            mock_data.append(sample)
        
        # åˆ›å»ºä¸´æ—¶æ•°æ®æ–‡ä»¶
        import pickle
        temp_data_path = './temp_test_data.pickle'
        with open(temp_data_path, 'wb') as f:
            pickle.dump(mock_data, f)
        
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        loader = SpeakerIndependentDataLoader(temp_data_path)
        
        # æµ‹è¯•æ•°æ®åˆ’åˆ†
        train_data, val_data, test_data = loader.create_speaker_independent_splits(0, n_folds=3)
        
        assert len(train_data) > 0, "è®­ç»ƒæ•°æ®ä¸ºç©º"
        assert len(val_data) > 0, "éªŒè¯æ•°æ®ä¸ºç©º" 
        assert len(test_data) > 0, "æµ‹è¯•æ•°æ®ä¸ºç©º"
        
        # éªŒè¯è¯´è¯äººæ— é‡å 
        train_speakers = set([s.get('speaker', '') for s in train_data])
        test_speakers = set([s.get('speaker', '') for s in test_data])
        
        assert len(train_speakers.intersection(test_speakers)) == 0, "è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¯´è¯äººæœ‰é‡å "
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(temp_data_path)
        
        print("âœ… è¯´è¯äººæ— å…³æ•°æ®å¤„ç†æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ è¯´è¯äººæ— å…³æ•°æ®å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        if os.path.exists('./temp_test_data.pickle'):
            os.remove('./temp_test_data.pickle')
        return False

def test_training_components():
    """æµ‹è¯•è®­ç»ƒç»„ä»¶"""
    print("ğŸ§ª æµ‹è¯•è®­ç»ƒç»„ä»¶...")
    
    try:
        # æµ‹è¯•æŸå¤±å‡½æ•°è®¡ç®—
        from train_enhanced import AdvancedTrainer
        
        # åˆ›å»ºæµ‹è¯•å‚æ•°
        class Args:
            def __init__(self):
                self.data_path = './Train_data_org.pickle'
                self.cuda = False  # æµ‹è¯•æ—¶ä½¿ç”¨CPU
                self.hidden_layer = 64  # å‡å°æ¨¡å‹ä»¥åŠ å¿«æµ‹è¯•
                self.out_class = 4
                self.dia_layers = 1
                self.dropout = 0.3
                self.attention = True
                self.speaker_norm = True
                self.speaker_adversarial = True
                self.freeze_layers = 3
                self.adversarial_weight = 0.1
                self.l2_reg = 1e-5
                self.n_folds = 3
        
        args = Args()
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„æ¨¡å‹è¾“å‡º
        batch_size = 4
        mock_outputs = {
            'emotion_logits': torch.randn(batch_size, 4),
            'speaker_logits': torch.randn(batch_size, 10),
            'attention_weights': None,
            'global_features': torch.randn(batch_size, 256)
        }
        
        emotion_targets = torch.randint(0, 4, (batch_size,))
        speaker_targets = torch.randint(0, 10, (batch_size,))
        
        # æµ‹è¯•æŸå¤±è®¡ç®—ï¼ˆä¸éœ€è¦å®Œæ•´çš„trainerï¼Œåªæµ‹è¯•æŸå¤±å‡½æ•°é€»è¾‘ï¼‰
        emotion_loss = torch.nn.functional.cross_entropy(mock_outputs['emotion_logits'], emotion_targets)
        speaker_loss = torch.nn.functional.cross_entropy(mock_outputs['speaker_logits'], speaker_targets)
        
        total_loss = emotion_loss + args.adversarial_weight * speaker_loss
        
        assert total_loss.item() > 0, "æŸå¤±è®¡ç®—å¼‚å¸¸"
        
        print("âœ… è®­ç»ƒç»„ä»¶æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_visualization_imports():
    """æµ‹è¯•å¯è§†åŒ–ç›¸å…³å¯¼å…¥"""
    print("ğŸ§ª æµ‹è¯•å¯è§†åŒ–ç»„ä»¶å¯¼å…¥...")
    
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
        from sklearn.metrics import confusion_matrix, classification_report
        from sklearn.manifold import TSNE
        
        # æµ‹è¯•ä¸­æ–‡å­—ä½“è®¾ç½®
        import matplotlib
        matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
        
        # åˆ›å»ºç®€å•æµ‹è¯•å›¾
        fig, ax = plt.subplots(1, 1, figsize=(6, 4))
        ax.plot([1, 2, 3], [1, 4, 2])
        ax.set_title('æµ‹è¯•å›¾è¡¨')
        plt.close(fig)
        
        print("âœ… å¯è§†åŒ–ç»„ä»¶å¯¼å…¥æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–ç»„ä»¶å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_compatibility():
    """æµ‹è¯•æ¨¡å‹å…¼å®¹æ€§"""
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹å…¼å®¹æ€§...")
    
    try:
        # æµ‹è¯•æ˜¯å¦èƒ½æ­£ç¡®å¯¼å…¥transformers
        from transformers import HubertModel
        
        # æµ‹è¯•æ˜¯å¦èƒ½åˆ›å»ºHuBERTæ¨¡å‹ï¼ˆä¸ä¸‹è½½ï¼Œåªæµ‹è¯•å¯¼å…¥ï¼‰
        print("  - HuBERTå¯¼å…¥æ­£å¸¸")
        
        # æµ‹è¯•PyTorchç‰ˆæœ¬å…¼å®¹æ€§
        torch_version = torch.__version__
        print(f"  - PyTorchç‰ˆæœ¬: {torch_version}")
        
        # æµ‹è¯•CUDAå¯ç”¨æ€§
        cuda_available = torch.cuda.is_available()
        print(f"  - CUDAå¯ç”¨: {cuda_available}")
        if cuda_available:
            print(f"  - CUDAè®¾å¤‡æ•°: {torch.cuda.device_count()}")
        
        print("âœ… æ¨¡å‹å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºç³»ç»ŸåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    test_results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("æ¨¡å‹å…¼å®¹æ€§", test_model_compatibility),
        ("å¯è§†åŒ–ç»„ä»¶å¯¼å…¥", test_visualization_imports),
        ("å¢å¼ºGRUæ¨¡å‹", test_enhanced_gru),
        ("è¯´è¯äººæ— å…³æ•°æ®å¤„ç†", test_speaker_independent_data),
        ("è®­ç»ƒç»„ä»¶", test_training_components),
    ]
    
    for test_name, test_func in tests:
        print(f"\\nğŸ“‹ {test_name}")
        print("-" * 40)
        try:
            result = test_func()
            test_results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å¼‚å¸¸: {e}")
            test_results.append((test_name, False))
    
    # æ±‡æ€»ç»“æœ
    print("\\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:<20}: {status}")
        if result:
            passed += 1
    
    print("-" * 60)
    print(f"æ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¢å¼ºç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        print("\\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   1. å‡†å¤‡IEMOCAPæ•°æ®æ–‡ä»¶ (Train_data_org.pickle)")
        print("   2. è¿è¡Œè®­ç»ƒ: python train_enhanced.py")
        print("   3. è¯„ä¼°æ€§èƒ½: python evaluate_speaker_independence.py")
    else:
        print(f"\\nâš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶ã€‚")
        print("\\nğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("   - æ£€æŸ¥Pythonç¯å¢ƒå’Œä¾èµ–åŒ…")
        print("   - ç¡®è®¤PyTorchå’Œtransformersç‰ˆæœ¬å…¼å®¹")
        print("   - æ£€æŸ¥CUDAç¯å¢ƒé…ç½®")
    
    print("=" * 60)
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)


