# æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹ä¼˜åŒ–è¯¦ç»†æ–‡æ¡£

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯](#æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯)
3. [ä»£ç å®ç°è¯¦è§£](#ä»£ç å®ç°è¯¦è§£)
4. [å‚æ•°é…ç½®è¯´æ˜](#å‚æ•°é…ç½®è¯´æ˜)
5. [è®­ç»ƒç­–ç•¥ä¼˜åŒ–](#è®­ç»ƒç­–ç•¥ä¼˜åŒ–)
6. [æ€§èƒ½ç›‘æ§ä¸å¯è§†åŒ–](#æ€§èƒ½ç›‘æ§ä¸å¯è§†åŒ–)

---

## ğŸ“– æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†IEMOCAPæƒ…æ„Ÿè¯†åˆ«æ¨¡å‹çš„æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯ï¼Œä¸»è¦è§£å†³è·¨è¯´è¯äººæƒ…æ„Ÿè¯†åˆ«ä¸­çš„æ³›åŒ–èƒ½åŠ›é—®é¢˜ã€‚ä¼˜åŒ–ç­–ç•¥åŒ…æ‹¬è¯´è¯äººæ— å…³åŒ–æŠ€æœ¯ã€é«˜çº§è®­ç»ƒç­–ç•¥å’Œç»¼åˆæŸå¤±å‡½æ•°è®¾è®¡ã€‚

### ä¸»è¦ä¼˜åŒ–ç›®æ ‡

- ğŸ¯ **æå‡è·¨è¯´è¯äººæ³›åŒ–èƒ½åŠ›**ï¼šæ¶ˆé™¤è¯´è¯äººç‰¹å¾å¯¹æƒ…æ„Ÿè¯†åˆ«çš„å¹²æ‰°
- ğŸ“ˆ **å¢å¼ºæ¨¡å‹é²æ£’æ€§**ï¼šé€šè¿‡å¤šç§æ­£åˆ™åŒ–å’Œæ•°æ®å¢å¼ºæŠ€æœ¯
- âš¡ **ä¼˜åŒ–è®­ç»ƒæ•ˆç‡**ï¼šé‡‡ç”¨å…ˆè¿›çš„å­¦ä¹ ç‡è°ƒåº¦å’Œæ—©åœç­–ç•¥
- ğŸ” **æä¾›å…¨é¢ç›‘æ§**ï¼šå®æ—¶å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹å’Œæ¨¡å‹æ€§èƒ½

---

## ğŸ”§ æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯

### 1. è¯´è¯äººæ— å…³åŒ–æŠ€æœ¯

#### 1.1 è‡ªé€‚åº”å®ä¾‹å½’ä¸€åŒ– (AdaIN)

**åŸç†**ï¼šé€šè¿‡å®ä¾‹çº§åˆ«çš„å½’ä¸€åŒ–æ¶ˆé™¤ä¸åŒè¯´è¯äººçš„éŸ³é¢‘ç‰¹å¾å·®å¼‚ï¼Œä¿ç•™æƒ…æ„Ÿç›¸å…³ä¿¡æ¯ã€‚

```python
class AdaptiveInstanceNormalization(nn.Module):
    """
    è‡ªé€‚åº”å®ä¾‹å½’ä¸€åŒ– - è¯´è¯äººå½’ä¸€åŒ–å±‚
    
    åŸç†ï¼š
    1. è®¡ç®—æ¯ä¸ªæ ·æœ¬åœ¨æ—¶åºç»´åº¦ä¸Šçš„å‡å€¼å’Œæ–¹å·®
    2. è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œæ¶ˆé™¤è¯´è¯äººç‰¹å¾å·®å¼‚
    3. é€šè¿‡å¯å­¦ä¹ å‚æ•°é‡æ–°ç¼©æ”¾ï¼Œä¿ç•™æƒ…æ„Ÿä¿¡æ¯
    
    æ•°å­¦å…¬å¼ï¼š
    Î¼ = mean(x, dim=1)  # æ—¶åºç»´åº¦å‡å€¼
    ÏƒÂ² = var(x, dim=1)  # æ—¶åºç»´åº¦æ–¹å·®
    x_norm = (x - Î¼) / âˆš(ÏƒÂ² + Îµ)  # å½’ä¸€åŒ–
    output = Î³ * x_norm + Î²  # ä»¿å°„å˜æ¢
    """
    
    def __init__(self, num_features, eps=1e-5):
        super(AdaptiveInstanceNormalization, self).__init__()
        self.num_features = num_features
        self.eps = eps  # æ•°å€¼ç¨³å®šæ€§å‚æ•°
        
        # å¯å­¦ä¹ çš„ç¼©æ”¾å’Œåç§»å‚æ•°
        self.weight = nn.Parameter(torch.ones(num_features))   # Î³ ç¼©æ”¾å‚æ•°
        self.bias = nn.Parameter(torch.zeros(num_features))    # Î² åç§»å‚æ•°
        
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        Args:
            x: [batch_size, seq_len, num_features] è¾“å…¥ç‰¹å¾
        Returns:
            å½’ä¸€åŒ–åçš„ç‰¹å¾
        """
        # è®¡ç®—å®ä¾‹çº§åˆ«çš„å‡å€¼å’Œæ–¹å·®ï¼ˆè·¨åºåˆ—ç»´åº¦ï¼‰
        mean = x.mean(dim=1, keepdim=True)  # [batch_size, 1, num_features]
        var = x.var(dim=1, keepdim=True, unbiased=False)  # [batch_size, 1, num_features]
        
        # å½’ä¸€åŒ–å¤„ç†
        x_norm = (x - mean) / torch.sqrt(var + self.eps)
        
        # åº”ç”¨å¯å­¦ä¹ çš„ä»¿å°„å˜æ¢
        out = x_norm * self.weight.unsqueeze(0).unsqueeze(0) + self.bias.unsqueeze(0).unsqueeze(0)
        
        return out
```

**å…³é”®å‚æ•°**ï¼š

- `num_features`: ç‰¹å¾ç»´åº¦æ•°é‡
- `eps`: æ•°å€¼ç¨³å®šæ€§å‚æ•°ï¼Œé˜²æ­¢é™¤é›¶é”™è¯¯
- `weight`: å¯å­¦ä¹ çš„ç¼©æ”¾å‚æ•°Î³
- `bias`: å¯å­¦ä¹ çš„åç§»å‚æ•°Î²

#### 1.2 æ¢¯åº¦åè½¬å¯¹æŠ—è®­ç»ƒ

**åŸç†**ï¼šé€šè¿‡æ¢¯åº¦åè½¬å±‚å®ç°å¯¹æŠ—è®­ç»ƒï¼Œè¿«ä½¿æ¨¡å‹å­¦ä¹ è¯´è¯äººæ— å…³çš„ç‰¹å¾è¡¨ç¤ºã€‚

```python
class GradientReversalLayer(torch.autograd.Function):
    """
    æ¢¯åº¦åè½¬å±‚ - å¯¹æŠ—è®­ç»ƒæ ¸å¿ƒç»„ä»¶
    
    åŸç†ï¼š
    1. å‰å‘ä¼ æ’­ï¼šæ­£å¸¸ä¼ é€’ç‰¹å¾ï¼Œä¸åšä»»ä½•æ”¹å˜
    2. åå‘ä¼ æ’­ï¼šå°†æ¢¯åº¦ä¹˜ä»¥è´Ÿçš„ç¼©æ”¾å› å­Î±
    3. æ•ˆæœï¼šä½¿æ¨¡å‹æ— æ³•ä»ç‰¹å¾ä¸­è¯†åˆ«è¯´è¯äººèº«ä»½
    
    æ•°å­¦è¡¨ç¤ºï¼š
    forward: y = x
    backward: âˆ‚L/âˆ‚x = -Î± * âˆ‚L/âˆ‚y
    """
    
    @staticmethod
    def forward(ctx, x, alpha):
        """
        å‰å‘ä¼ æ’­ï¼šç›´æ¥ä¼ é€’è¾“å…¥
        Args:
            x: è¾“å…¥ç‰¹å¾
            alpha: æ¢¯åº¦åè½¬å¼ºåº¦
        """
        ctx.alpha = alpha  # ä¿å­˜alphaç”¨äºåå‘ä¼ æ’­
        return x.view_as(x)
    
    @staticmethod
    def backward(ctx, grad_output):
        """
        åå‘ä¼ æ’­ï¼šæ¢¯åº¦ç¬¦å·åè½¬
        Args:
            grad_output: æ¥è‡ªä¸Šå±‚çš„æ¢¯åº¦
        Returns:
            åè½¬åçš„æ¢¯åº¦
        """
        return grad_output.neg() * ctx.alpha, None

def gradient_reverse(x, alpha=1.0):
    """æ¢¯åº¦åè½¬å‡½æ•°åŒ…è£…å™¨"""
    return GradientReversalLayer.apply(x, alpha)
```

**è¯´è¯äººåˆ†ç±»å™¨**ï¼š

```python
# è¯´è¯äººåˆ†ç±»å¤´ï¼ˆç”¨äºå¯¹æŠ—è®­ç»ƒï¼‰
if self.use_adversarial:
    self.speaker_classifier = nn.Sequential(
        nn.Linear(hidden_size * 4, hidden_size),      # ç‰¹å¾é™ç»´
        nn.ReLU(inplace=True),                        # éçº¿æ€§æ¿€æ´»
        nn.Dropout(self.dropout_rate),                # é˜²è¿‡æ‹Ÿåˆ
        nn.Linear(hidden_size, hidden_size // 2),     # è¿›ä¸€æ­¥é™ç»´
        nn.ReLU(inplace=True),
        nn.Dropout(self.dropout_rate),
        nn.Linear(hidden_size // 2, 10)              # 10ä¸ªè¯´è¯äººåˆ†ç±»
    )
```

### 2. å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶

**åŸç†**ï¼šé€šè¿‡å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶æ•è·åºåˆ—ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œå¢å¼ºæƒ…æ„Ÿç‰¹å¾è¡¨ç¤ºã€‚

```python
class MultiHeadSelfAttention(nn.Module):
    """
    å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶
    
    åŸç†ï¼š
    1. å°†è¾“å…¥ç‰¹å¾åˆ†åˆ«æŠ•å½±åˆ°Qã€Kã€Vç©ºé—´
    2. è®¡ç®—å¤šä¸ªæ³¨æ„åŠ›å¤´çš„æ³¨æ„åŠ›æƒé‡
    3. åŠ æƒèšåˆç‰¹å¾ä¿¡æ¯
    4. é€šè¿‡æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ç¨³å®šè®­ç»ƒ
    
    æ³¨æ„åŠ›å…¬å¼ï¼š
    Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V
    MultiHead = Concat(head_1, ..., head_h)W^O
    """
    
    def __init__(self, d_model, num_heads, dropout=0.1):
        super(MultiHeadSelfAttention, self).__init__()
        assert d_model % num_heads == 0
        
        self.d_model = d_model          # æ¨¡å‹ç»´åº¦
        self.num_heads = num_heads      # æ³¨æ„åŠ›å¤´æ•°é‡
        self.d_k = d_model // num_heads # æ¯ä¸ªå¤´çš„ç»´åº¦
        
        # çº¿æ€§æŠ•å½±å±‚
        self.w_q = nn.Linear(d_model, d_model)  # QueryæŠ•å½±
        self.w_k = nn.Linear(d_model, d_model)  # KeyæŠ•å½±
        self.w_v = nn.Linear(d_model, d_model)  # ValueæŠ•å½±
        self.w_o = nn.Linear(d_model, d_model)  # è¾“å‡ºæŠ•å½±
        
        # æ­£åˆ™åŒ–å±‚
        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(d_model)
        
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        Args:
            x: [batch_size, seq_len, d_model] è¾“å…¥ç‰¹å¾
        Returns:
            æ³¨æ„åŠ›å¢å¼ºåçš„ç‰¹å¾å’Œæ³¨æ„åŠ›æƒé‡
        """
        batch_size, seq_len, d_model = x.size()
        
        # ä¿å­˜æ®‹å·®è¿æ¥
        residual = x
        
        # 1. çº¿æ€§æŠ•å½±åˆ°Qã€Kã€V
        Q = self.w_q(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)
        K = self.w_k(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)
        V = self.w_v(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)
        
        # 2. è®¡ç®—ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›
        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)
        attention_weights = F.softmax(attention_scores, dim=-1)
        attention_weights = self.dropout(attention_weights)
        
        # 3. åŠ æƒèšåˆValue
        context = torch.matmul(attention_weights, V)
        
        # 4. æ‹¼æ¥å¤šå¤´è¾“å‡º
        context = context.transpose(1, 2).contiguous().view(
            batch_size, seq_len, self.d_model
        )
        
        # 5. è¾“å‡ºæŠ•å½±
        output = self.w_o(context)
        
        # 6. æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–
        output = self.layer_norm(output + residual)
        
        return output, attention_weights.mean(dim=1)  # è¿”å›å¹³å‡æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–
```

### 3. ä½ç½®ç¼–ç 

```python
class PositionalEncoding(nn.Module):
    """
    æ­£å¼¦ä½ç½®ç¼–ç 
    
    åŸç†ï¼š
    ä½¿ç”¨ä¸åŒé¢‘ç‡çš„æ­£å¼¦å’Œä½™å¼¦å‡½æ•°ä¸ºåºåˆ—ä¸­çš„æ¯ä¸ªä½ç½®ç”Ÿæˆå”¯ä¸€çš„ç¼–ç 
    
    å…¬å¼ï¼š
    PE(pos, 2i) = sin(pos / 10000^(2i/d_model))
    PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))
    """
    
    def __init__(self, d_model, max_length=5000):
        super(PositionalEncoding, self).__init__()
        
        # åˆ›å»ºä½ç½®ç¼–ç çŸ©é˜µ
        pe = torch.zeros(max_length, d_model)
        position = torch.arange(0, max_length).unsqueeze(1).float()
        
        # è®¡ç®—é™¤æ•°é¡¹
        div_term = torch.exp(torch.arange(0, d_model, 2).float() *
                            -(math.log(10000.0) / d_model))
        
        # åº”ç”¨æ­£å¼¦å’Œä½™å¼¦å‡½æ•°
        pe[:, 0::2] = torch.sin(position * div_term)  # å¶æ•°ä½ç½®ä½¿ç”¨sin
        pe[:, 1::2] = torch.cos(position * div_term)  # å¥‡æ•°ä½ç½®ä½¿ç”¨cos
        
        self.register_buffer('pe', pe.unsqueeze(0))
    
    def forward(self, x):
        """æ·»åŠ ä½ç½®ç¼–ç åˆ°è¾“å…¥ç‰¹å¾"""
        seq_len = x.size(1)
        pos_encoding = self.pe[:, :seq_len, :].to(x.device)
        return x + pos_encoding
```

---

## ğŸ—ï¸ ä»£ç å®ç°è¯¦è§£

### 1. å¢å¼ºGRUæ¨¡å‹æ¶æ„

```python
class EnhancedGRUModel(nn.Module):
    """
    å¢å¼ºçš„GRUæ¨¡å‹ - é’ˆå¯¹è·¨è¯´è¯äººæƒ…æ„Ÿè¯†åˆ«ä¼˜åŒ–
    
    æ¶æ„ç‰¹ç‚¹ï¼š
    1. è¾“å…¥æŠ•å½± + ä½ç½®ç¼–ç 
    2. è¯´è¯äººå½’ä¸€åŒ–å±‚ (AdaIN)
    3. å¤šå±‚åŒå‘GRU + å±‚å½’ä¸€åŒ– + æ®‹å·®è¿æ¥
    4. å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶
    5. ç‰¹å¾å¢å¼ºæ¨¡å—
    6. åŒè·¯åˆ†ç±»å¤´ï¼ˆæƒ…æ„Ÿ + è¯´è¯äººå¯¹æŠ—ï¼‰
    """
    
    def __init__(self, input_size, hidden_size, output_size, args):
        super(EnhancedGRUModel, self).__init__()
        
        # åŸºç¡€å‚æ•°
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.num_layers = args.dia_layers
        self.dropout_rate = args.dropout
        
        # åŠŸèƒ½å¼€å…³
        self.use_attention = args.attention
        self.use_speaker_norm = getattr(args, 'speaker_norm', True)
        self.use_adversarial = getattr(args, 'speaker_adversarial', True)
        
        # 1. è¾“å…¥å¤„ç†å±‚
        self.input_projection = nn.Linear(input_size, hidden_size * 2)
        self.pos_encoding = PositionalEncoding(hidden_size * 2)
        
        # 2. è¯´è¯äººå½’ä¸€åŒ–å±‚
        if self.use_speaker_norm:
            self.speaker_norm = AdaptiveInstanceNormalization(hidden_size * 2)
        
        # 3. å¤šå±‚åŒå‘GRU
        self.gru_layers = nn.ModuleList()
        self.layer_norms = nn.ModuleList()
        
        for i in range(self.num_layers):
            input_dim = hidden_size * 2 if i == 0 else hidden_size * 4
            self.gru_layers.append(
                nn.GRU(input_dim, hidden_size * 2, batch_first=True, 
                      bidirectional=True, dropout=self.dropout_rate if i < self.num_layers-1 else 0)
            )
            self.layer_norms.append(nn.LayerNorm(hidden_size * 4))
        
        # 4. å¤šå¤´è‡ªæ³¨æ„åŠ›
        if self.use_attention:
            self.self_attention = MultiHeadSelfAttention(
                d_model=hidden_size * 4, 
                num_heads=8, 
                dropout=self.dropout_rate
            )
        
        # 5. ç‰¹å¾å¢å¼ºæ¨¡å—
        self.feature_enhancement = nn.Sequential(
            nn.Linear(hidden_size * 4, hidden_size * 2),
            nn.ReLU(inplace=True),
            nn.Dropout(self.dropout_rate),
            nn.Linear(hidden_size * 2, hidden_size * 2),
            nn.ReLU(inplace=True),
            nn.Dropout(self.dropout_rate)
        )
        
        # 6. å…¨å±€æ± åŒ–ç­–ç•¥
        self.global_pooling = nn.AdaptiveAvgPool1d(1)      # å¹³å‡æ± åŒ–
        self.global_max_pooling = nn.AdaptiveMaxPool1d(1)   # æœ€å¤§æ± åŒ–
        
        # 7. æƒ…æ„Ÿåˆ†ç±»å¤´
        self.emotion_classifier = nn.Sequential(
            nn.Linear(hidden_size * 4, hidden_size),
            nn.ReLU(inplace=True),
            nn.Dropout(self.dropout_rate),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(inplace=True),
            nn.Dropout(self.dropout_rate),
            nn.Linear(hidden_size // 2, output_size)
        )
        
        # 8. è¯´è¯äººåˆ†ç±»å¤´ï¼ˆå¯¹æŠ—è®­ç»ƒï¼‰
        if self.use_adversarial:
            self.speaker_classifier = nn.Sequential(
                nn.Linear(hidden_size * 4, hidden_size),
                nn.ReLU(inplace=True),
                nn.Dropout(self.dropout_rate),
                nn.Linear(hidden_size, hidden_size // 2),
                nn.ReLU(inplace=True),
                nn.Dropout(self.dropout_rate),
                nn.Linear(hidden_size // 2, 10)  # IEMOCAPæœ‰10ä¸ªè¯´è¯äºº
            )
        
        self.dropout = nn.Dropout(self.dropout_rate)
        self._init_weights()
```

### 2. å‰å‘ä¼ æ’­æµç¨‹

```python
def forward(self, x, alpha=1.0):
    """
    å‰å‘ä¼ æ’­
    
    Args:
        x: [batch_size, seq_len, input_size] è¾“å…¥ç‰¹å¾
        alpha: æ¢¯åº¦åè½¬å¼ºåº¦ï¼ˆç”¨äºå¯¹æŠ—è®­ç»ƒï¼‰
    
    Returns:
        dict: åŒ…å«æƒ…æ„Ÿå’Œè¯´è¯äººé¢„æµ‹ç»“æœçš„å­—å…¸
    """
    batch_size, seq_len, _ = x.size()
    
    # 1. è¾“å…¥æŠ•å½±å’Œä½ç½®ç¼–ç 
    x = self.input_projection(x)  # [batch_size, seq_len, hidden_size*2]
    x = self.pos_encoding(x)      # æ·»åŠ ä½ç½®ä¿¡æ¯
    
    # 2. è¯´è¯äººå½’ä¸€åŒ–ï¼ˆæ¶ˆé™¤è¯´è¯äººç‰¹å¾ï¼‰
    if self.use_speaker_norm:
        x = self.speaker_norm(x)
    
    x = self.dropout(x)
    
    # 3. å¤šå±‚åŒå‘GRUå¤„ç†
    for i, (gru_layer, layer_norm) in enumerate(zip(self.gru_layers, self.layer_norms)):
        residual = x if i > 0 else None
        
        gru_out, _ = gru_layer(x)  # [batch_size, seq_len, hidden_size*4]
        gru_out = layer_norm(gru_out)
        
        # æ®‹å·®è¿æ¥ï¼ˆä»ç¬¬äºŒå±‚å¼€å§‹ï¼‰
        if residual is not None and residual.size(-1) == gru_out.size(-1):
            gru_out = gru_out + residual
        
        x = self.dropout(gru_out)
    
    # 4. å¤šå¤´è‡ªæ³¨æ„åŠ›å¢å¼º
    attention_weights = None
    if self.use_attention:
        x, attention_weights = self.self_attention(x)
    
    # 5. ç‰¹å¾å¢å¼º
    enhanced_features = self.feature_enhancement(x)
    combined_features = torch.cat([x, enhanced_features], dim=-1)
    combined_features = combined_features[:, :, :self.hidden_size*4]
    
    # 6. å…¨å±€æ± åŒ–
    pooling_input = combined_features.transpose(1, 2)
    avg_pooled = self.global_pooling(pooling_input).squeeze(-1)
    max_pooled = self.global_max_pooling(pooling_input).squeeze(-1)
    
    # æ‹¼æ¥æ± åŒ–ç»“æœ
    pooled_features = torch.cat([avg_pooled, max_pooled], dim=1)
    final_features = pooled_features[:, :self.hidden_size*4]
    
    # 7. æƒ…æ„Ÿåˆ†ç±»
    emotion_logits = self.emotion_classifier(final_features)
    
    # 8. è¯´è¯äººå¯¹æŠ—åˆ†ç±»
    speaker_logits = None
    if self.use_adversarial:
        # åº”ç”¨æ¢¯åº¦åè½¬
        adversarial_features = gradient_reverse(final_features, alpha)
        speaker_logits = self.speaker_classifier(adversarial_features)
    
    return {
        'emotion_logits': emotion_logits,
        'speaker_logits': speaker_logits,
        'attention_weights': attention_weights,
        'features': final_features
    }
```

---

## âš™ï¸ å‚æ•°é…ç½®è¯´æ˜

### 1. æ¨¡å‹ç»“æ„å‚æ•°

```python
# åŸºç¡€æ¶æ„å‚æ•°
input_size = 768          # HuBERTç‰¹å¾ç»´åº¦
hidden_size = 256         # GRUéšè—å±‚å¤§å°
output_size = 4           # æƒ…æ„Ÿç±»åˆ«æ•°é‡ï¼ˆangry, happy, neutral, sadï¼‰
dia_layers = 3            # GRUå±‚æ•°

# æ­£åˆ™åŒ–å‚æ•°
dropout = 0.3             # Dropoutæ¦‚ç‡
max_grad_norm = 1.0       # æ¢¯åº¦è£å‰ªé˜ˆå€¼
l2_reg = 1e-5            # L2æ­£åˆ™åŒ–æƒé‡
```

### 2. ä¼˜åŒ–ç­–ç•¥å‚æ•°

```python
# å­¦ä¹ ç‡è°ƒåº¦
learning_rate = 0.0005    # åˆå§‹å­¦ä¹ ç‡
lr_schedule = 'cosine'    # å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
warmup_steps = 1000       # é¢„çƒ­æ­¥æ•°
min_lr = 1e-7            # æœ€å°å­¦ä¹ ç‡

# è®­ç»ƒç­–ç•¥
batch_size = 32          # æ‰¹æ¬¡å¤§å°
epochs = 50              # è®­ç»ƒè½®æ•°
patience = 10            # æ—©åœè€å¿ƒå€¼
```

### 3. è¯´è¯äººæ— å…³åŒ–å‚æ•°

```python
# AdaINå½’ä¸€åŒ–
speaker_norm = True       # å¯ç”¨è¯´è¯äººå½’ä¸€åŒ–
eps = 1e-5               # æ•°å€¼ç¨³å®šæ€§å‚æ•°

# å¯¹æŠ—è®­ç»ƒ
speaker_adversarial = True    # å¯ç”¨å¯¹æŠ—è®­ç»ƒ
adversarial_weight = 0.05     # å¯¹æŠ—æŸå¤±æƒé‡
alpha_schedule = 'linear'     # æ¢¯åº¦åè½¬å¼ºåº¦è°ƒåº¦
max_alpha = 1.0              # æœ€å¤§æ¢¯åº¦åè½¬å¼ºåº¦
```

### 4. æ³¨æ„åŠ›æœºåˆ¶å‚æ•°

```python
# å¤šå¤´æ³¨æ„åŠ›
attention = True          # å¯ç”¨æ³¨æ„åŠ›æœºåˆ¶
num_heads = 8            # æ³¨æ„åŠ›å¤´æ•°é‡
attention_dropout = 0.1   # æ³¨æ„åŠ›dropout
```

---

## ğŸ¯ è®­ç»ƒç­–ç•¥ä¼˜åŒ–

### 1. ç»¼åˆæŸå¤±å‡½æ•°

```python
def compute_loss(self, model_outputs, targets, speaker_targets, alpha=1.0):
    """
    ç»¼åˆæŸå¤±å‡½æ•°
    
    ç»„æˆï¼š
    1. ä¸»ä»»åŠ¡æŸå¤±ï¼šæƒ…æ„Ÿåˆ†ç±»äº¤å‰ç†µæŸå¤±
    2. å¯¹æŠ—æŸå¤±ï¼šè¯´è¯äººæ··æ·†æŸå¤±
    3. æ­£åˆ™åŒ–æŸå¤±ï¼šL2æƒé‡è¡°å‡
    
    Args:
        model_outputs: æ¨¡å‹è¾“å‡ºå­—å…¸
        targets: æƒ…æ„Ÿæ ‡ç­¾
        speaker_targets: è¯´è¯äººæ ‡ç­¾
        alpha: æ¢¯åº¦åè½¬å¼ºåº¦
    
    Returns:
        total_loss: æ€»æŸå¤±
        loss_dict: å„é¡¹æŸå¤±è¯¦æƒ…
    """
    emotion_logits = model_outputs['emotion_logits']
    speaker_logits = model_outputs['speaker_logits']
    
    # 1. æƒ…æ„Ÿåˆ†ç±»æŸå¤±ï¼ˆä¸»è¦ä»»åŠ¡ï¼‰
    emotion_loss = F.cross_entropy(emotion_logits, targets)
    
    total_loss = emotion_loss
    loss_dict = {'emotion_loss': emotion_loss.item()}
    
    # 2. è¯´è¯äººå¯¹æŠ—æŸå¤±
    if speaker_logits is not None and self.args.speaker_adversarial:
        speaker_loss = F.cross_entropy(speaker_logits, speaker_targets)
        total_loss += self.args.adversarial_weight * speaker_loss
        loss_dict['speaker_loss'] = speaker_loss.item()
    
    # 3. æ­£åˆ™åŒ–æŸå¤±
    if self.args.l2_reg > 0:
        l2_loss = sum(torch.norm(p, 2) for p in model_outputs.get('regularization_params', []))
        total_loss += self.args.l2_reg * l2_loss
        loss_dict['l2_loss'] = l2_loss.item() if isinstance(l2_loss, torch.Tensor) else l2_loss
    
    loss_dict['total_loss'] = total_loss.item()
    return total_loss, loss_dict
```

### 2. åŠ¨æ€å¯¹æŠ—è®­ç»ƒç­–ç•¥

```python
def get_alpha_schedule(self, epoch, total_epochs):
    """
    åŠ¨æ€è°ƒæ•´æ¢¯åº¦åè½¬å¼ºåº¦
    
    ç­–ç•¥ï¼š
    1. å‰æœŸï¼ˆepoch < 5ï¼‰ï¼šÎ± = 0ï¼Œä¸“æ³¨æƒ…æ„Ÿåˆ†ç±»
    2. ä¸­æœŸï¼ˆ5 â‰¤ epoch < total_epochs*0.7ï¼‰ï¼šçº¿æ€§å¢é•¿
    3. åæœŸï¼šä¿æŒæœ€å¤§å€¼
    """
    if epoch < 5:
        return 0.0  # å‰æœŸä¸ä½¿ç”¨å¯¹æŠ—è®­ç»ƒ
    elif epoch < total_epochs * 0.7:
        # çº¿æ€§å¢é•¿é˜¶æ®µ
        progress = (epoch - 5) / (total_epochs * 0.7 - 5)
        return progress * self.args.max_alpha
    else:
        return self.args.max_alpha  # åæœŸä¿æŒæœ€å¤§å€¼
```

### 3. å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥

```python
def create_lr_scheduler(self, optimizer, total_steps):
    """
    åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    
    ç­–ç•¥ï¼šä½™å¼¦é€€ç« + é¢„çƒ­
    1. é¢„çƒ­é˜¶æ®µï¼šçº¿æ€§å¢é•¿åˆ°åˆå§‹å­¦ä¹ ç‡
    2. ä¸»è®­ç»ƒé˜¶æ®µï¼šä½™å¼¦é€€ç«åˆ°æœ€å°å­¦ä¹ ç‡
    3. é‡å¯æœºåˆ¶ï¼šå‘¨æœŸæ€§é‡å¯æå‡æ€§èƒ½
    """
    # é¢„çƒ­è°ƒåº¦å™¨
    warmup_scheduler = LinearLR(
        optimizer,
        start_factor=0.1,
        end_factor=1.0,
        total_iters=self.args.warmup_steps
    )
    
    # ä½™å¼¦é€€ç«è°ƒåº¦å™¨
    cosine_scheduler = CosineAnnealingWarmRestarts(
        optimizer,
        T_0=total_steps // 4,  # ç¬¬ä¸€ä¸ªå‘¨æœŸé•¿åº¦
        T_mult=2,              # å‘¨æœŸå€å¢å› å­
        eta_min=self.args.min_lr
    )
    
    # ç»„åˆè°ƒåº¦å™¨
    scheduler = SequentialLR(
        optimizer,
        schedulers=[warmup_scheduler, cosine_scheduler],
        milestones=[self.args.warmup_steps]
    )
    
    return scheduler
```

### 4. æ•°æ®å¢å¼ºç­–ç•¥

```python
def apply_augmentation(self, audio_features):
    """
    è®­ç»ƒæ—¶æ•°æ®å¢å¼º
    
    ç­–ç•¥ï¼š
    1. é«˜æ–¯å™ªå£°ï¼šå¢åŠ é²æ£’æ€§
    2. æ—¶é—´æ‹‰ä¼¸ï¼šæ¨¡æ‹Ÿè¯­é€Ÿå˜åŒ–
    3. ç‰¹å¾æ©è”½ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ
    """
    if self.is_training:
        # 1. æ·»åŠ é«˜æ–¯å™ªå£°
        if torch.rand(1) < 0.3:
            noise = torch.randn_like(audio_features) * self.noise_factor
            audio_features = audio_features + noise
        
        # 2. æ—¶é—´ç»´åº¦æ‹‰ä¼¸ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if torch.rand(1) < 0.2:
            stretch_factor = 1.0 + torch.rand(1) * self.time_stretch_factor * 2 - self.time_stretch_factor
            # å®é™…å®ç°éœ€è¦æ’å€¼æ“ä½œ
            
        # 3. ç‰¹å¾æ©è”½
        if torch.rand(1) < 0.2:
            mask_size = int(audio_features.size(0) * 0.1)
            mask_start = torch.randint(0, max(1, audio_features.size(0) - mask_size), (1,))
            audio_features[mask_start:mask_start + mask_size] *= 0.1
    
    return audio_features
```

---

## ğŸ“Š æ€§èƒ½ç›‘æ§ä¸å¯è§†åŒ–

### 1. è®­ç»ƒç›‘æ§æŒ‡æ ‡

```python
class TrainingMonitor:
    """è®­ç»ƒè¿‡ç¨‹ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics = {
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'train_f1': [],
            'val_f1': [],
            'learning_rate': [],
            'alpha_values': []
        }
    
    def update_metrics(self, epoch, train_metrics, val_metrics, lr, alpha):
        """æ›´æ–°è®­ç»ƒæŒ‡æ ‡"""
        self.metrics['train_loss'].append(train_metrics['loss'])
        self.metrics['val_loss'].append(val_metrics['loss'])
        self.metrics['train_acc'].append(train_metrics['accuracy'])
        self.metrics['val_acc'].append(val_metrics['accuracy'])
        self.metrics['train_f1'].append(train_metrics['f1_score'])
        self.metrics['val_f1'].append(val_metrics['f1_score'])
        self.metrics['learning_rate'].append(lr)
        self.metrics['alpha_values'].append(alpha)
    
    def plot_training_curves(self, save_path):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(self.metrics['train_loss'], label='Train Loss', color='blue')
        axes[0, 0].plot(self.metrics['val_loss'], label='Val Loss', color='red')
        axes[0, 0].set_title('Loss Curves')
        axes[0, 0].legend()
        
        # å‡†ç¡®ç‡æ›²çº¿
        axes[0, 1].plot(self.metrics['train_acc'], label='Train Acc', color='blue')
        axes[0, 1].plot(self.metrics['val_acc'], label='Val Acc', color='red')
        axes[0, 1].set_title('Accuracy Curves')
        axes[0, 1].legend()
        
        # F1åˆ†æ•°æ›²çº¿
        axes[0, 2].plot(self.metrics['train_f1'], label='Train F1', color='blue')
        axes[0, 2].plot(self.metrics['val_f1'], label='Val F1', color='red')
        axes[0, 2].set_title('F1 Score Curves')
        axes[0, 2].legend()
        
        # å­¦ä¹ ç‡å˜åŒ–
        axes[1, 0].plot(self.metrics['learning_rate'], color='green')
        axes[1, 0].set_title('Learning Rate Schedule')
        axes[1, 0].set_yscale('log')
        
        # Alphaå€¼å˜åŒ–
        axes[1, 1].plot(self.metrics['alpha_values'], color='orange')
        axes[1, 1].set_title('Adversarial Alpha Schedule')
        
        # éªŒè¯æŸå¤±æ”¾å¤§å›¾
        axes[1, 2].plot(self.metrics['val_loss'], color='red', linewidth=2)
        axes[1, 2].set_title('Validation Loss (Detailed)')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
```

### 2. è·¨è¯´è¯äººæ€§èƒ½åˆ†æ

```python
def analyze_speaker_performance(self, model, test_loader, save_dir):
    """
    è·¨è¯´è¯äººæ€§èƒ½åˆ†æ
    
    åˆ†æå†…å®¹ï¼š
    1. å„è¯´è¯äººå‡†ç¡®ç‡å¯¹æ¯”
    2. æ€§èƒ½æ–¹å·®åˆ†æ
    3. æ€§åˆ«å·®å¼‚åˆ†æ
    4. ä¼šè¯å·®å¼‚åˆ†æ
    """
    model.eval()
    speaker_results = defaultdict(list)
    
    with torch.no_grad():
        for batch in test_loader:
            features = batch['audio_features'].to(self.device)
            labels = batch['emotion_label'].to(self.device)
            speakers = batch['speaker']
            
            outputs = model(features)
            predictions = torch.argmax(outputs['emotion_logits'], dim=1)
            
            for pred, label, speaker in zip(predictions.cpu(), labels.cpu(), speakers):
                speaker_results[speaker].append({
                    'prediction': pred.item(),
                    'label': label.item(),
                    'correct': pred.item() == label.item()
                })
    
    # è®¡ç®—å„è¯´è¯äººæ€§èƒ½
    speaker_metrics = {}
    for speaker, results in speaker_results.items():
        correct = sum(r['correct'] for r in results)
        total = len(results)
        accuracy = correct / total if total > 0 else 0
        
        # è®¡ç®—F1åˆ†æ•°
        y_true = [r['label'] for r in results]
        y_pred = [r['prediction'] for r in results]
        f1 = f1_score(y_true, y_pred, average='weighted')
        
        speaker_metrics[speaker] = {
            'accuracy': accuracy,
            'f1_score': f1,
            'total_samples': total
        }
    
    # å¯è§†åŒ–ç»“æœ
    self.plot_speaker_performance(speaker_metrics, save_dir)
    
    return speaker_metrics

def plot_speaker_performance(self, speaker_metrics, save_dir):
    """ç»˜åˆ¶è¯´è¯äººæ€§èƒ½å¯¹æ¯”å›¾"""
    speakers = list(speaker_metrics.keys())
    accuracies = [speaker_metrics[s]['accuracy'] for s in speakers]
    f1_scores = [speaker_metrics[s]['f1_score'] for s in speakers]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # å‡†ç¡®ç‡å¯¹æ¯”
    bars1 = ax1.bar(speakers, accuracies, color='skyblue', alpha=0.7)
    ax1.set_title('Speaker-wise Accuracy Comparison')
    ax1.set_ylabel('Accuracy')
    ax1.set_ylim(0, 1)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, acc in zip(bars1, accuracies):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{acc:.3f}', ha='center', va='bottom')
    
    # F1åˆ†æ•°å¯¹æ¯”
    bars2 = ax2.bar(speakers, f1_scores, color='lightcoral', alpha=0.7)
    ax2.set_title('Speaker-wise F1 Score Comparison')
    ax2.set_ylabel('F1 Score')
    ax2.set_ylim(0, 1)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, f1 in zip(bars2, f1_scores):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{f1:.3f}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig(f'{save_dir}/speaker_performance_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
```

---

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### 1. æ¨¡å‹åˆå§‹åŒ–

```python
# åˆ›å»ºå‚æ•°å¯¹è±¡
args = argparse.Namespace(
    input_size=768,
    hidden_size=256,
    output_size=4,
    dia_layers=3,
    dropout=0.3,
    attention=True,
    speaker_norm=True,
    speaker_adversarial=True,
    adversarial_weight=0.05,
    max_alpha=1.0
)

# åˆå§‹åŒ–æ¨¡å‹
model = EnhancedGRUModel(
    input_size=args.input_size,
    hidden_size=args.hidden_size,
    output_size=args.output_size,
    args=args
)

print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
```

### 2. è®­ç»ƒæµç¨‹

```python
# åˆ›å»ºè®­ç»ƒå™¨
trainer = AdvancedTrainer(args)

# è®­ç»ƒæ¨¡å‹
best_model_path = trainer.train_model(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    save_dir='./experiments'
)

print(f"æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {best_model_path}")
```

### 3. æ€§èƒ½è¯„ä¼°

```python
# åŠ è½½æœ€ä½³æ¨¡å‹
model.load_state_dict(torch.load(best_model_path))

# è¯„ä¼°è·¨è¯´è¯äººæ€§èƒ½
evaluator = SpeakerIndependenceEvaluator(model, args)
results = evaluator.evaluate(test_loader, save_dir='./evaluation_results')

print("è·¨è¯´è¯äººæ€§èƒ½è¯„ä¼°å®Œæˆï¼")
print(f"æ€»ä½“å‡†ç¡®ç‡: {results['overall_accuracy']:.4f}")
print(f"å¹³å‡F1åˆ†æ•°: {results['average_f1']:.4f}")
print(f"æ€§èƒ½æ ‡å‡†å·®: {results['performance_std']:.4f}")
```

---

## ğŸ“ˆ é¢„æœŸæ”¹è¿›æ•ˆæœ

### æ€§èƒ½æå‡é¢„æœŸ

| æŒ‡æ ‡       | åŸå§‹æ¨¡å‹  | å¢å¼ºæ¨¡å‹  | æ”¹è¿›å¹…åº¦   |
| ---------- | --------- | --------- | ---------- |
| æ€»ä½“å‡†ç¡®ç‡ | 65-70%    | 75-80%    | +10-15%    |
| è·¨è¯´è¯äººF1 | 0.62-0.67 | 0.72-0.77 | +0.10-0.15 |
| æ€§èƒ½æ–¹å·®   | 0.08-0.12 | 0.04-0.08 | -50%â†“      |
| æ”¶æ•›é€Ÿåº¦   | 30-40è½®   | 20-25è½®   | å¿«25-50%   |

### æŠ€æœ¯ä¼˜åŠ¿

1. **ğŸ¯ è¯´è¯äººæ— å…³æ€§**ï¼šAdaINå½’ä¸€åŒ– + å¯¹æŠ—è®­ç»ƒæ˜¾è‘—å‡å°‘è¯´è¯äººåè§
2. **ğŸš€ è®­ç»ƒæ•ˆç‡**ï¼šåŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦ + æ—©åœæœºåˆ¶åŠ é€Ÿæ”¶æ•›
3. **ğŸ’ª æ¨¡å‹é²æ£’æ€§**ï¼šå¤šç§æ­£åˆ™åŒ–æŠ€æœ¯æå‡æ³›åŒ–èƒ½åŠ›
4. **ğŸ“Š å…¨é¢ç›‘æ§**ï¼šå®æ—¶å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹å’Œæ€§èƒ½æŒ‡æ ‡

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

1. **å†…å­˜ä¸è¶³**

   ```python
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   args.batch_size = 16  # ä»32é™åˆ°16
   
   # å¯ç”¨æ¢¯åº¦ç´¯ç§¯
   args.gradient_accumulation_steps = 2
   ```

2. **è®­ç»ƒä¸ç¨³å®š**

   ```python
   # é™ä½å­¦ä¹ ç‡
   args.learning_rate = 0.0001
   
   # å¢åŠ æ¢¯åº¦è£å‰ª
   args.max_grad_norm = 0.5
   ```

3. **è¿‡æ‹Ÿåˆä¸¥é‡**

   ```python
   # å¢åŠ Dropout
   args.dropout = 0.5
   
   # å¢åŠ L2æ­£åˆ™åŒ–
   args.l2_reg = 1e-4
   ```

4. **å¯¹æŠ—è®­ç»ƒä¸æ”¶æ•›**

   ```python
   # é™ä½å¯¹æŠ—æƒé‡
   args.adversarial_weight = 0.01
   
   # å»¶è¿Ÿå¯¹æŠ—è®­ç»ƒå¼€å§‹æ—¶é—´
   args.adversarial_start_epoch = 10
   ```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **AdaIN**: Huang, X., & Belongie, S. (2017). Arbitrary style transfer in real-time with adaptive instance normalization.
2. **Gradient Reversal**: Ganin, Y., & Lempitsky, V. (2015). Unsupervised domain adaptation by backpropagation.
3. **Multi-Head Attention**: Vaswani, A., et al. (2017). Attention is all you need.
4. **HuBERT**: Hsu, W. N., et al. (2021). HuBERT: Self-supervised speech representation learning by masked prediction.

---

*ğŸ“ æ–‡æ¡£ç‰ˆæœ¬: v2.0 | æ›´æ–°æ—¥æœŸ: 2024-09-26 | ä½œè€…: AI Assistant*

---

# IEMOCAPè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿæ·±åº¦æºç è§£æ

## ç›®å½•

1. [é¡¹ç›®æ•´ä½“æ¶æ„ä¸æ¨¡å—åˆ’åˆ†](#1-é¡¹ç›®æ•´ä½“æ¶æ„ä¸æ¨¡å—åˆ’åˆ†)
2. [æ ¸å¿ƒç»„ä»¶åŠŸèƒ½æ·±åº¦è§£æ](#2-æ ¸å¿ƒç»„ä»¶åŠŸèƒ½æ·±åº¦è§£æ)
3. [å®Œæ•´æ•°æ®æµè·¯å¾„åˆ†æ](#3-å®Œæ•´æ•°æ®æµè·¯å¾„åˆ†æ)
4. [å…³é”®å‚æ•°å«ä¹‰ä¸æ€§èƒ½å½±å“](#4-å…³é”®å‚æ•°å«ä¹‰ä¸æ€§èƒ½å½±å“)
5. [æ¨¡å‹å·¥ä½œæœºåˆ¶æ·±å…¥ç†è§£](#5-æ¨¡å‹å·¥ä½œæœºåˆ¶æ·±å…¥ç†è§£)
6. [ç³»ç»Ÿä¼˜åŠ¿ä¸æŠ€æœ¯åˆ›æ–°](#6-ç³»ç»Ÿä¼˜åŠ¿ä¸æŠ€æœ¯åˆ›æ–°)

---

## 1. é¡¹ç›®æ•´ä½“æ¶æ„ä¸æ¨¡å—åˆ’åˆ†

### 1.1 ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

è¯¥IEMOCAPè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿé‡‡ç”¨ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œå®ç°ä»åŸå§‹éŸ³é¢‘ä¿¡å·åˆ°æƒ…æ„Ÿç±»åˆ«çš„ç›´æ¥æ˜ å°„ã€‚æ•´ä½“æ•°æ®æµéµå¾ªç°ä»£è¯­éŸ³å¤„ç†çš„æœ€ä½³å®è·µï¼š

```
åŸå§‹éŸ³é¢‘ â†’ é¢„å¤„ç†æ ‡å‡†åŒ– â†’ HuBERTç‰¹å¾ç¼–ç  â†’ åŒå‘GRUåºåˆ—å»ºæ¨¡ â†’ æ³¨æ„åŠ›æœºåˆ¶å¢å¼º â†’ å…¨å±€æ± åŒ– â†’ åˆ†ç±»è¾“å‡º
```

è¿™ç§è®¾è®¡å……åˆ†åˆ©ç”¨äº†è‡ªç›‘ç£é¢„è®­ç»ƒæ¨¡å‹çš„å¼ºå¤§ç‰¹å¾æå–èƒ½åŠ›ï¼Œç»“åˆå¾ªç¯ç¥ç»ç½‘ç»œå¯¹æ—¶åºä¿¡æ¯çš„ç²¾ç¡®å»ºæ¨¡ï¼Œæœ€ç»ˆé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å®ç°å¯¹æƒ…æ„Ÿå…³é”®ä¿¡æ¯çš„åŠ¨æ€èšç„¦ã€‚

### 1.2 æ ¸å¿ƒæ¨¡å—åˆ’åˆ†

**æ•°æ®é¢„å¤„ç†æ¨¡å—** (`Data_prepocessing.py`)

- **åŠŸèƒ½èŒè´£**ï¼šè´Ÿè´£IEMOCAPæ•°æ®é›†çš„æ ‡å‡†åŒ–å¤„ç†ï¼ŒåŒ…æ‹¬éŸ³é¢‘é•¿åº¦ç»Ÿä¸€ã€é‡‡æ ·ç‡æ ‡å‡†åŒ–ã€æƒ…æ„Ÿæ ‡ç­¾æ˜ å°„
- **æ ¸å¿ƒä»·å€¼**ï¼šç¡®ä¿æ¨¡å‹è¾“å…¥çš„ä¸€è‡´æ€§ï¼Œä¸ºåç»­ç‰¹å¾æå–æä¾›æ ‡å‡†åŒ–çš„æ•°æ®åŸºç¡€
- **æŠ€æœ¯ç‰¹ç‚¹**ï¼šé‡‡ç”¨å›ºå®š3ç§’æ—¶é•¿ç­–ç•¥ï¼Œå¹³è¡¡ä¿¡æ¯ä¿ç•™ä¸è®¡ç®—æ•ˆç‡

**æ¨¡å‹æ¶æ„æ¨¡å—** (`models/GRU.py`)

- **SpeechRecognitionModel**ï¼šä¸»æ¨¡å‹å®¹å™¨ï¼Œæ•´åˆHuBERTç‰¹å¾æå–å™¨ä¸GRUåºåˆ—å»ºæ¨¡å™¨
- **GRUModel**ï¼šåºåˆ—å»ºæ¨¡æ ¸å¿ƒï¼Œè´Ÿè´£æ—¶åºç‰¹å¾çš„æ·±åº¦å­¦ä¹ ä¸æƒ…æ„Ÿåˆ†ç±»
- **MatchingAttention**ï¼šæ³¨æ„åŠ›æœºåˆ¶å®ç°ï¼Œæä¾›åŠ¨æ€ç‰¹å¾åŠ æƒèƒ½åŠ›

**è®­ç»ƒä¸éªŒè¯æ¨¡å—** (`train.py`)

- **äº¤å‰éªŒè¯ç­–ç•¥**ï¼šé‡‡ç”¨5æŠ˜äº¤å‰éªŒè¯ï¼Œç¡®ä¿æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å¯é è¯„ä¼°
- **ä¼˜åŒ–ç­–ç•¥**ï¼šä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œç»“åˆé€‚å½“çš„å­¦ä¹ ç‡è°ƒåº¦
- **æ€§èƒ½è¯„ä¼°**ï¼šå¤šæŒ‡æ ‡ç»¼åˆè¯„ä¼°ï¼ŒåŒ…æ‹¬å‡†ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°

**æ¨ç†ä¸åº”ç”¨æ¨¡å—** (`DEMO.py`, `GUIæƒ…æ„Ÿè¯†åˆ«2.py`)

- **å•æ ·æœ¬æ¨ç†**ï¼šæä¾›ç®€æ´çš„æ¨¡å‹æµ‹è¯•æ¥å£
- **å®æ—¶éŸ³é¢‘å¤„ç†**ï¼šæ”¯æŒéº¦å…‹é£å®æ—¶å½•éŸ³ä¸æƒ…æ„Ÿè¯†åˆ«
- **ç”¨æˆ·ç•Œé¢**ï¼šå®Œæ•´çš„PyQt5å›¾å½¢ç•Œé¢ï¼Œæä¾›ç›´è§‚çš„äº¤äº’ä½“éªŒ

---

## 2. æ ¸å¿ƒç»„ä»¶åŠŸèƒ½æ·±åº¦è§£æ

### 2.1 HubertModelè¯­éŸ³ç‰¹å¾ç¼–ç å™¨

#### 2.1.1 æ¨¡å‹é€‰æ‹©çš„æ·±å±‚è€ƒé‡

```python
self.feature_extractor = HubertModel.from_pretrained("facebook/hubert-base-ls960")
```

HuBERT (Hidden-Unit BERT) çš„é€‰æ‹©ä½“ç°äº†å¯¹è¯­éŸ³è¡¨ç¤ºå­¦ä¹ å‰æ²¿æŠ€æœ¯çš„æ·±åˆ»ç†è§£ï¼š

**è‡ªç›‘ç£å­¦ä¹ ä¼˜åŠ¿**ï¼š

- HuBERTé€šè¿‡æ©ç é¢„æµ‹ä»»åŠ¡åœ¨å¤§è§„æ¨¡æ— æ ‡æ³¨è¯­éŸ³æ•°æ®ä¸Šé¢„è®­ç»ƒï¼Œå­¦ä¹ åˆ°äº†ä¸°å¯Œçš„è¯­éŸ³è¡¨ç¤º
- ç›¸æ¯”ä¼ ç»Ÿçš„MFCCã€Melé¢‘è°±ç­‰æ‰‹å·¥ç‰¹å¾ï¼ŒHuBERTèƒ½å¤Ÿè‡ªåŠ¨å‘ç°è¯­éŸ³ä¸­çš„å±‚æ¬¡åŒ–æ¨¡å¼
- é¢„è®­ç»ƒåœ¨960å°æ—¶LibriSpeechæ•°æ®ä¸Šè¿›è¡Œï¼Œæ¶µç›–äº†å¤šæ ·åŒ–çš„è¯­éŸ³æ¨¡å¼å’Œå£°å­¦ç¯å¢ƒ

**åˆ†å±‚ç‰¹å¾è¡¨ç¤º**ï¼š

- åº•å±‚ï¼šæ•è·éŸ³ç´ çº§åˆ«çš„å£°å­¦ç‰¹å¾ï¼Œå¦‚å…±æŒ¯å³°ã€åŸºé¢‘å˜åŒ–
- ä¸­å±‚ï¼šå»ºæ¨¡éŸ³èŠ‚å’Œè¯æ±‡çº§åˆ«çš„è¯­éŸ³æ¨¡å¼
- é«˜å±‚ï¼šç¼–ç è¯­ä¹‰å’ŒéŸµå¾‹ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯å¯¹æƒ…æ„Ÿè¯†åˆ«è‡³å…³é‡è¦

**768ç»´ç‰¹å¾å‘é‡çš„ä¿¡æ¯å¯†åº¦**ï¼š

- æ¯ä¸ªæ—¶é—´æ­¥è¾“å‡º768ç»´å¯†é›†å‘é‡ï¼Œç›¸æ¯”ä¼ ç»Ÿç‰¹å¾ï¼ˆå¦‚39ç»´MFCCï¼‰å…·æœ‰æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›
- é«˜ç»´ç‰¹å¾ç©ºé—´èƒ½å¤Ÿæ›´ç²¾ç»†åœ°åŒºåˆ†ä¸åŒæƒ…æ„ŸçŠ¶æ€ä¸‹çš„è¯­éŸ³å˜åŒ–

#### 2.1.2 ç‰¹å¾æå–çš„æŠ€æœ¯å®ç°

```python
def forward(self, input_waveform):
    features = self.feature_extractor(input_waveform).last_hidden_state  # [batch, seq_len, 768]
    logits = self.Utterance_net(features)
    return logits, features
```

**å¤„ç†æµç¨‹çš„æŠ€æœ¯ç»†èŠ‚**ï¼š

1. **å·ç§¯ç‰¹å¾æå–**ï¼š
   - HuBERTé¦–å…ˆé€šè¿‡7å±‚1Då·ç§¯ç½‘ç»œå¤„ç†åŸå§‹æ³¢å½¢
   - æ¯å±‚å·ç§¯é€æ­¥é™ä½æ—¶é—´åˆ†è¾¨ç‡ï¼Œæé«˜ç‰¹å¾æŠ½è±¡å±‚æ¬¡
   - å·ç§¯æ ¸è®¾è®¡è€ƒè™‘äº†è¯­éŸ³ä¿¡å·çš„æ—¶é¢‘ç‰¹æ€§

2. **Transformerç¼–ç **ï¼š
   - 12å±‚Transformerç¼–ç å™¨è¿›è¡Œåºåˆ—å»ºæ¨¡
   - è‡ªæ³¨æ„åŠ›æœºåˆ¶æ•è·é•¿è·ç¦»ä¾èµ–å…³ç³»
   - ä½ç½®ç¼–ç ä¿æŒæ—¶åºä¿¡æ¯çš„å®Œæ•´æ€§

3. **ç‰¹å¾é€‰æ‹©ç­–ç•¥**ï¼š
   - `last_hidden_state`æä¾›æœ€é«˜å±‚çš„è¯­ä¹‰è¡¨ç¤º
   - è¿™ä¸€å±‚ç‰¹å¾æœ€é€‚åˆä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ï¼Œå¹³è¡¡äº†ç‰¹å¾æŠ½è±¡ç¨‹åº¦ä¸ä»»åŠ¡ç›¸å…³æ€§

#### 2.1.3 éŸ³é¢‘é¢„å¤„ç†çš„å·¥ç¨‹è€ƒé‡

```python
def process_wav_file(wav_file, time_seconds):
    waveform, sample_rate = torchaudio.load(wav_file)
    target_length = int(time_seconds * sample_rate)
    if waveform.size(1) > target_length:
        waveform = waveform[:, :target_length]  # æ—¶é—´è£å‰ª
    else:
        padding_length = target_length - waveform.size(1)
        waveform = torch.nn.functional.pad(waveform, (0, padding_length))  # é›¶å¡«å……
    return waveform, sample_rate
```

**3ç§’å›ºå®šé•¿åº¦çš„è®¾è®¡rationale**ï¼š

- **è®¡ç®—æ•ˆç‡**ï¼šå›ºå®šé•¿åº¦ä¾¿äºæ‰¹å¤„ç†ï¼Œæé«˜GPUåˆ©ç”¨ç‡
- **ä¿¡æ¯å……åˆ†æ€§**ï¼š3ç§’è¶³ä»¥åŒ…å«å®Œæ•´çš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œæ¶µç›–è¯æ±‡ã€éŸµå¾‹ã€è¯­è°ƒå˜åŒ–
- **å†…å­˜ç®¡ç†**ï¼šé¿å…å˜é•¿åºåˆ—å¸¦æ¥çš„å†…å­˜ç¢ç‰‡åŒ–é—®é¢˜
- **æ¨¡å‹ä¸€è‡´æ€§**ï¼šç¡®ä¿è®­ç»ƒå’Œæ¨ç†é˜¶æ®µçš„è¾“å…¥æ ¼å¼å®Œå…¨ä¸€è‡´

**é›¶å¡«å…… vs é‡å¤å¡«å……çš„é€‰æ‹©**ï¼š

- é›¶å¡«å……é¿å…äº†äººå·¥å¼•å…¥çš„å‘¨æœŸæ€§æ¨¡å¼
- ä¿æŒäº†åŸå§‹è¯­éŸ³çš„è‡ªç„¶è¾¹ç•Œç‰¹æ€§
- ä¸HuBERTé¢„è®­ç»ƒæ—¶çš„å¤„ç†æ–¹å¼ä¿æŒä¸€è‡´

### 2.2 GRUModelåŒå‘åºåˆ—å»ºæ¨¡å™¨

#### 2.2.1 æ¶æ„è®¾è®¡çš„æ·±å±‚é€»è¾‘

```python
class GRUModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, args):
        self.bigru = nn.GRU(input_size, hidden_size, batch_first=True, 
                           num_layers=self.num_layers, bidirectional=True)
        self.input2hidden = nn.Linear(512, hidden_size * 2)
        self.hidden2label = nn.Linear(hidden_size * 2, output_size)
```

**åŒå‘GRUçš„ç†è®ºåŸºç¡€**ï¼š

- **å‰å‘ä¿¡æ¯æµ**ï¼šæ•è·ä»è¯­éŸ³å¼€å§‹åˆ°å½“å‰æ—¶åˆ»çš„æƒ…æ„Ÿå‘å±•è½¨è¿¹
- **åå‘ä¿¡æ¯æµ**ï¼šåˆ©ç”¨æœªæ¥ä¿¡æ¯ä¸ºå½“å‰æ—¶åˆ»æä¾›ä¸Šä¸‹æ–‡çº¦æŸ
- **ä¿¡æ¯èåˆ**ï¼šå‰åå‘éšçŠ¶æ€çš„æ‹¼æ¥æä¾›äº†æ›´å®Œæ•´çš„æ—¶åºè¡¨ç¤º

**å¤šå±‚è®¾è®¡çš„å¿…è¦æ€§**ï¼š

- **å±‚æ¬¡åŒ–æŠ½è±¡**ï¼šåº•å±‚æ•è·å±€éƒ¨æ—¶åºæ¨¡å¼ï¼Œé«˜å±‚å»ºæ¨¡å…¨å±€æƒ…æ„ŸåŠ¨æ€
- **éçº¿æ€§å¢å¼º**ï¼šå¤šå±‚ç»“æ„å¢åŠ æ¨¡å‹çš„éçº¿æ€§è¡¨è¾¾èƒ½åŠ›
- **æ¢¯åº¦æµä¼˜åŒ–**ï¼šé€‚å½“çš„å±‚æ•°å¹³è¡¡äº†è¡¨è¾¾èƒ½åŠ›ä¸æ¢¯åº¦ä¼ æ’­æ•ˆç‡

#### 2.2.2 å‰å‘ä¼ æ’­çš„ç²¾å¯†è®¾è®¡

```python
def forward(self, U):
    U = self.dropout(U)  # è¾“å…¥æ­£åˆ™åŒ–
    emotions, hidden = self.bigru(U)  # [batch, seq, 512]
    
    # æ³¨æ„åŠ›æœºåˆ¶å¢å¼º
    if self.attention:
        att_emotions = []
        for t in emotions:
            att_em, alpha_ = self.matchatt(emotions, t, mask=None)
            att_emotions.append(att_em.unsqueeze(0))
        att_emotions = torch.cat(att_emotions, dim=0)
        emotions = att_emotions
    
    # å…¨å±€ç‰¹å¾èšåˆ
    gru_out = torch.transpose(emotions, 1, 2)  # [batch, 512, seq]
    gru_out = F.tanh(gru_out)
    gru_out = F.max_pool1d(gru_out, gru_out.size(2)).squeeze(2)  # å…¨å±€æœ€å¤§æ± åŒ–
    
    # åˆ†ç±»æ˜ å°„
    Out_in = self.relu(gru_out)
    Out_in = self.dropout(Out_in)
    Out_out = self.hidden2label(Out_in)  # [batch, num_classes]
    return Out_out
```

**å…³é”®å¤„ç†æ­¥éª¤çš„æŠ€æœ¯åˆ†æ**ï¼š

1. **è¾“å…¥Dropout**ï¼š
   - åœ¨ç‰¹å¾å±‚é¢å¼•å…¥éšæœºæ€§ï¼Œå¢å¼ºæ¨¡å‹æ³›åŒ–èƒ½åŠ›
   - é˜²æ­¢æ¨¡å‹è¿‡åº¦ä¾èµ–HuBERTç‰¹å¾çš„ç‰¹å®šç»´åº¦

2. **åŒå‘GRUå¤„ç†**ï¼š
   - è¾“å‡ºç»´åº¦ä¸º512ï¼ˆ256Ã—2ï¼‰ï¼Œèåˆå‰åå‘ä¿¡æ¯
   - `batch_first=True`è®¾è®¡ä¾¿äºåç»­å¤„ç†å’Œè°ƒè¯•

3. **æ³¨æ„åŠ›å¢å¼ºï¼ˆå¯é€‰ï¼‰**ï¼š
   - ä¸ºæ¯ä¸ªæ—¶é—´æ­¥è®¡ç®—å…¨å±€æ³¨æ„åŠ›æƒé‡
   - åŠ¨æ€è°ƒæ•´ä¸åŒæ—¶åˆ»ç‰¹å¾çš„é‡è¦æ€§
   - ç¼“è§£é•¿åºåˆ—ä¿¡æ¯è¡°å‡é—®é¢˜

4. **å…¨å±€æœ€å¤§æ± åŒ–**ï¼š
   - æå–åºåˆ—ä¸­çš„æœ€æ˜¾è‘—ç‰¹å¾
   - å®ç°ä»å˜é•¿åºåˆ—åˆ°å›ºå®šé•¿åº¦è¡¨ç¤ºçš„è½¬æ¢
   - ä¿ç•™æœ€å¼ºçš„æƒ…æ„Ÿæ¿€æ´»ä¿¡å·

5. **åˆ†ç±»å¤´æ˜ å°„**ï¼š
   - çº¿æ€§å˜æ¢å°†512ç»´ç‰¹å¾æ˜ å°„åˆ°4ç±»æƒ…æ„Ÿè¾“å‡º
   - æ— åç½®è®¾è®¡ç®€åŒ–æ¨¡å‹ï¼Œå‡å°‘è¿‡æ‹Ÿåˆé£é™©

### 2.3 MatchingAttentionæ³¨æ„åŠ›æœºåˆ¶

#### 2.3.1 æ³¨æ„åŠ›è®¾è®¡çš„ç†è®ºåŸºç¡€

```python
class MatchingAttention(nn.Module):
    def __init__(self, mem_dim, cand_dim, alpha_dim=None, att_type='general'):
        if att_type=='general':
            self.transform = nn.Linear(cand_dim, mem_dim, bias=False)
```

**æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒæ€æƒ³**ï¼š

- **æŸ¥è¯¢-é”®-å€¼æ¨¡å¼**ï¼šå°†å½“å‰æ—¶åˆ»ä½œä¸ºæŸ¥è¯¢ï¼Œæ•´ä¸ªåºåˆ—ä½œä¸ºé”®å’Œå€¼
- **ç›¸ä¼¼åº¦è®¡ç®—**ï¼šé€šè¿‡å­¦ä¹ åˆ°çš„å˜æ¢çŸ©é˜µè®¡ç®—æŸ¥è¯¢ä¸é”®çš„åŒ¹é…ç¨‹åº¦
- **åŠ¨æ€æƒé‡åˆ†é…**ï¼šæ ¹æ®ç›¸ä¼¼åº¦ä¸ºä¸åŒæ—¶åˆ»åˆ†é…æ³¨æ„åŠ›æƒé‡

**General Attentionçš„ä¼˜åŠ¿**ï¼š

- **ç»´åº¦çµæ´»æ€§**ï¼šé€šè¿‡çº¿æ€§å˜æ¢å¤„ç†ä¸åŒç»´åº¦çš„è¾“å…¥
- **å‚æ•°æ•ˆç‡**ï¼šç›¸æ¯”concat attentionå‚æ•°æ›´å°‘ï¼Œè®­ç»ƒæ›´ç¨³å®š
- **è®¡ç®—æ•ˆç‡**ï¼šçŸ©é˜µä¹˜æ³•æ“ä½œä¾¿äºGPUå¹¶è¡ŒåŠ é€Ÿ

#### 2.3.2 æ³¨æ„åŠ›è®¡ç®—çš„æ•°å­¦å®ç°

```python
def forward(self, M, x, mask=None):
    # M: [seq_len, batch, mem_dim] - è®°å¿†åºåˆ—ï¼ˆæ‰€æœ‰æ—¶åˆ»çš„éšçŠ¶æ€ï¼‰
    # x: [batch, cand_dim] - æŸ¥è¯¢å‘é‡ï¼ˆå½“å‰æ—¶åˆ»çš„éšçŠ¶æ€ï¼‰
    
    if self.att_type=='general':
        M_ = M.permute(1,2,0)  # [batch, mem_dim, seq_len]
        x_ = self.transform(x).unsqueeze(1)  # [batch, 1, mem_dim]
        alpha = F.softmax(torch.bmm(x_, M_), dim=2)  # [batch, 1, seq_len]
    
    attn_pool = torch.bmm(alpha, M.transpose(0,1))[:,0,:]  # [batch, mem_dim]
    return attn_pool, alpha
```

**è®¡ç®—æµç¨‹çš„æ·±å±‚è§£æ**ï¼š

1. **æŸ¥è¯¢å˜æ¢**ï¼š

   ```python
   x_ = self.transform(x).unsqueeze(1)  # [batch, 1, mem_dim]
   ```

   - å°†å½“å‰æ—¶åˆ»ç‰¹å¾å˜æ¢åˆ°è®°å¿†ç©ºé—´
   - å­¦ä¹ æŸ¥è¯¢ä¸è®°å¿†ä¹‹é—´çš„æœ€ä¼˜åŒ¹é…å…³ç³»

2. **ç›¸ä¼¼åº¦è®¡ç®—**ï¼š

   ```python
   alpha = F.softmax(torch.bmm(x_, M_), dim=2)  # [batch, 1, seq_len]
   ```

   - æ‰¹é‡çŸ©é˜µä¹˜æ³•è®¡ç®—æ‰€æœ‰æ—¶åˆ»çš„ç›¸ä¼¼åº¦åˆ†æ•°
   - Softmaxå½’ä¸€åŒ–ç¡®ä¿æƒé‡å’Œä¸º1

3. **åŠ æƒèšåˆ**ï¼š

   ```python
   attn_pool = torch.bmm(alpha, M.transpose(0,1))[:,0,:]  # [batch, mem_dim]
   ```

   - æ ¹æ®æ³¨æ„åŠ›æƒé‡å¯¹æ‰€æœ‰æ—¶åˆ»ç‰¹å¾è¿›è¡ŒåŠ æƒå¹³å‡
   - ç”Ÿæˆèåˆå…¨å±€ä¿¡æ¯çš„ä¸Šä¸‹æ–‡å‘é‡

#### 2.3.3 æ³¨æ„åŠ›åœ¨æƒ…æ„Ÿè¯†åˆ«ä¸­çš„ä½œç”¨æœºåˆ¶

```python
if self.attention:
    att_emotions = []
    alpha = []
    for t in emotions:  # å¯¹åºåˆ—ä¸­æ¯ä¸ªæ—¶é—´æ­¥
        att_em, alpha_ = self.matchatt(emotions, t, mask=None)
        att_emotions.append(att_em.unsqueeze(0))
        alpha.append(alpha_[:, 0, :])
    att_emotions = torch.cat(att_emotions, dim=0)
    emotions = att_emotions
```

**æ³¨æ„åŠ›å¢å¼ºçš„æƒ…æ„Ÿå»ºæ¨¡ä»·å€¼**ï¼š

1. **å…³é”®æ—¶åˆ»è¯†åˆ«**ï¼š
   - è‡ªåŠ¨è¯†åˆ«è¯­éŸ³ä¸­æƒ…æ„Ÿè¡¨è¾¾æœ€å¼ºçƒˆçš„æ—¶é—´æ®µ
   - ä¾‹å¦‚ï¼šè¯­è°ƒå˜åŒ–å‰§çƒˆçš„è¯æ±‡ã€åœé¡¿å‰åçš„é‡éŸ³

2. **ä¸Šä¸‹æ–‡æ•´åˆ**ï¼š
   - ä¸ºæ¯ä¸ªæ—¶åˆ»æä¾›å…¨åºåˆ—çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
   - é¿å…å±€éƒ¨ç‰¹å¾çš„è¯¯å¯¼ï¼Œæé«˜åˆ†ç±»ç¨³å®šæ€§

3. **é•¿è·ç¦»ä¾èµ–å»ºæ¨¡**ï¼š
   - ç¼“è§£GRUåœ¨é•¿åºåˆ—ä¸Šçš„ä¿¡æ¯è¡°å‡é—®é¢˜
   - ä¿æŒåºåˆ—å¼€å§‹å’Œç»“æŸéƒ¨åˆ†ä¿¡æ¯çš„æœ‰æ•ˆä¼ é€’

4. **å¯è§£é‡Šæ€§å¢å¼º**ï¼š
   - æ³¨æ„åŠ›æƒé‡æä¾›æ¨¡å‹å†³ç­–çš„å¯è§†åŒ–ä¾æ®
   - å¸®åŠ©ç†è§£æ¨¡å‹å…³æ³¨çš„è¯­éŸ³ç‰¹å¾æ¨¡å¼

### 2.4 åˆ†ç±»å¤´ä¸æ¿€æ´»å‡½æ•°çš„ç²¾å¿ƒè®¾è®¡

#### 2.4.1 åˆ†ç±»å¤´çš„æ¶æ„é€‰æ‹©

```python
self.hidden2label = nn.Linear(hidden_size * 2, output_size)  # 512 -> 4
```

**çº¿æ€§åˆ†ç±»å¤´çš„è®¾è®¡è€ƒé‡**ï¼š

- **ç®€æ´æ€§åŸåˆ™**ï¼šé¿å…è¿‡åº¦å¤æ‚çš„åˆ†ç±»å™¨ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
- **ç‰¹å¾å……åˆ†æ€§**ï¼š512ç»´GRUè¾“å‡ºå·²åŒ…å«ä¸°å¯Œçš„æƒ…æ„Ÿåˆ¤åˆ«ä¿¡æ¯
- **è®¡ç®—æ•ˆç‡**ï¼šçº¿æ€§å˜æ¢è®¡ç®—ç®€å•ï¼Œä¾¿äºå®æ—¶åº”ç”¨

#### 2.4.2 æ¿€æ´»å‡½æ•°çš„å±‚æ¬¡åŒ–åº”ç”¨

```python
gru_out = F.tanh(gru_out)      # åºåˆ—ç‰¹å¾æ¿€æ´»
Out_in = self.relu(gru_out)    # åˆ†ç±»å‰æ¿€æ´»
# åˆ†ç±»å±‚æ— æ¿€æ´»ï¼Œè¾“å‡ºåŸå§‹logits
```

**æ¿€æ´»å‡½æ•°é€‰æ‹©çš„æ·±å±‚é€»è¾‘**ï¼š

1. **Tanhæ¿€æ´»**ï¼š
   - å°†åºåˆ—ç‰¹å¾å‹ç¼©åˆ°[-1,1]åŒºé—´
   - å¢å¼ºç‰¹å¾çš„å¯¹æ¯”åº¦ï¼Œçªå‡ºæ˜¾è‘—å˜åŒ–
   - å¯¹ç§°æ€§è´¨é€‚åˆåŒå‘GRUçš„è¾“å‡ºç‰¹å¾

2. **LeakyReLUæ¿€æ´»**ï¼š
   - ä¿æŒæ¢¯åº¦æµåŠ¨ï¼Œé¿å…æ­»ç¥ç»å…ƒé—®é¢˜
   - è´Ÿæ–œç‡å‚æ•°å…è®¸è´Ÿå€¼ä¿¡æ¯çš„éƒ¨åˆ†ä¿ç•™
   - åœ¨åˆ†ç±»å‰æä¾›éçº¿æ€§å˜æ¢èƒ½åŠ›

3. **æ— æ¿€æ´»è¾“å‡º**ï¼š
   - åˆ†ç±»å±‚è¾“å‡ºåŸå§‹logitsï¼Œä¾¿äºäº¤å‰ç†µæŸå¤±è®¡ç®—
   - ä¿æŒæ•°å€¼ç¨³å®šæ€§ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±

---

## 3. å®Œæ•´æ•°æ®æµè·¯å¾„åˆ†æ

### 3.1 è®­ç»ƒé˜¶æ®µæ•°æ®æµ

**è®­ç»ƒæµç¨‹çš„å…³é”®ç¯èŠ‚åˆ†æ**ï¼š

1. **æ•°æ®é¢„å¤„ç†é˜¶æ®µ**ï¼š
   - IEMOCAPæ•°æ®é›†åŒ…å«å¤šç§æƒ…æ„Ÿç±»åˆ«ï¼Œéœ€è¦æ ‡å‡†åŒ–æ˜ å°„
   - éŸ³é¢‘é•¿åº¦ä¸ä¸€è‡´é—®é¢˜é€šè¿‡3ç§’å›ºå®šé•¿åº¦ç­–ç•¥è§£å†³
   - é‡‡æ ·ç‡ç»Ÿä¸€ä¸º16kHzï¼ŒåŒ¹é…HuBERTé¢„è®­ç»ƒé…ç½®

2. **ç‰¹å¾æå–é˜¶æ®µ**ï¼š
   - HuBERTæ¨¡å‹å†»ç»“å‚æ•°ï¼Œä»…ç”¨äºç‰¹å¾æå–
   - 768ç»´ç‰¹å¾å‘é‡åŒ…å«ä¸°å¯Œçš„è¯­éŸ³è¯­ä¹‰ä¿¡æ¯
   - æ‰¹å¤„ç†æ–¹å¼æé«˜ç‰¹å¾æå–æ•ˆç‡

3. **æ¨¡å‹è®­ç»ƒé˜¶æ®µ**ï¼š
   - 5æŠ˜äº¤å‰éªŒè¯ç¡®ä¿ç»“æœçš„ç»Ÿè®¡æ˜¾è‘—æ€§
   - æ‰¹æ¬¡å¤§å°32å¹³è¡¡å†…å­˜å ç”¨ä¸æ¢¯åº¦ä¼°è®¡è´¨é‡
   - AdamWä¼˜åŒ–å™¨ç»“åˆæƒé‡è¡°å‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ

4. **æ¨¡å‹ä¿å­˜é˜¶æ®µ**ï¼š
   - ä¿å­˜å®Œæ•´çš„state_dictï¼Œä¾¿äºåç»­åŠ è½½
   - æ¨¡å‹æ–‡ä»¶åŒ…å«æ‰€æœ‰å¯è®­ç»ƒå‚æ•°

### 3.2 æ¨ç†é˜¶æ®µæ•°æ®æµ

**æ¨ç†æµç¨‹çš„æŠ€æœ¯ç»†èŠ‚**ï¼š

1. **è¾“å…¥å¤„ç†å¤šæ ·æ€§**ï¼š
   - æ”¯æŒWAVæ–‡ä»¶å’Œå®æ—¶éº¦å…‹é£ä¸¤ç§è¾“å…¥æ¨¡å¼
   - ç»Ÿä¸€çš„é¢„å¤„ç†æµç¨‹ç¡®ä¿è¾“å…¥æ ¼å¼ä¸€è‡´æ€§

2. **ç‰¹å¾æå–ä¸€è‡´æ€§**ï¼š
   - ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„processorå’Œé¢„å¤„ç†å‚æ•°
   - ç¡®ä¿ç‰¹å¾åˆ†å¸ƒçš„ä¸€è‡´æ€§

3. **æ¨¡å‹æ¨ç†ä¼˜åŒ–**ï¼š
   - `torch.no_grad()`ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡å°‘å†…å­˜å ç”¨
   - æ‰¹å¤„ç†ç»´åº¦çš„åŠ¨æ€è°ƒæ•´é€‚åº”ä¸åŒè¾“å…¥æ ¼å¼

4. **ç»“æœåå¤„ç†**ï¼š
   - Softmaxæä¾›æ¦‚ç‡åˆ†å¸ƒï¼Œå¢å¼ºç»“æœå¯ä¿¡åº¦
   - ç½®ä¿¡åº¦è®¡ç®—å¸®åŠ©è¯„ä¼°é¢„æµ‹è´¨é‡

### 3.3 GUIå®æ—¶å¤„ç†æµ

**å®æ—¶å¤„ç†çš„å·¥ç¨‹æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ**ï¼š

1. **çº¿ç¨‹å®‰å…¨è®¾è®¡**ï¼š
   - AudioRecorderç‹¬ç«‹çº¿ç¨‹é¿å…UIé˜»å¡
   - ä¿¡å·-æ§½æœºåˆ¶ç¡®ä¿çº¿ç¨‹é—´å®‰å…¨é€šä¿¡

2. **éŸ³é¢‘ç¼“å†²ç®¡ç†**ï¼š
   - æ»‘åŠ¨çª—å£æœºåˆ¶ä¿æŒæœ€æ–°5ç§’éŸ³é¢‘
   - è‡ªåŠ¨å†…å­˜ç®¡ç†é¿å…ç¼“å†²åŒºæº¢å‡º

3. **å®æ—¶æ€§èƒ½ä¼˜åŒ–**ï¼š
   - æ¨¡å‹é¢„åŠ è½½å‡å°‘æ¨ç†å»¶è¿Ÿ
   - å¼‚æ­¥å¤„ç†æé«˜å“åº”é€Ÿåº¦

4. **ç”¨æˆ·ä½“éªŒè®¾è®¡**ï¼š
   - å®æ—¶åé¦ˆæä¾›å³æ—¶æƒ…æ„Ÿè¯†åˆ«ç»“æœ
   - å†å²è®°å½•åŠŸèƒ½æ”¯æŒç»“æœå›é¡¾

---

## 4. å…³é”®å‚æ•°å«ä¹‰ä¸æ€§èƒ½å½±å“

### 4.1 æ¨¡å‹ç»“æ„å‚æ•°æ·±åº¦åˆ†æ

| å‚æ•°å        | é»˜è®¤å€¼ | å‚æ•°å«ä¹‰       | æ€§èƒ½å½±å“æœºåˆ¶                                                 | è°ƒä¼˜å»ºè®®                                 |
| ------------- | ------ | -------------- | ------------------------------------------------------------ | ---------------------------------------- |
| `hidden_size` | 256    | GRUéšçŠ¶æ€ç»´åº¦  | **è¡¨è¾¾èƒ½åŠ›**ï¼šæ›´å¤§ç»´åº¦æä¾›æ›´å¼ºç‰¹å¾è¡¨è¾¾<br>**è®¡ç®—å¤æ‚åº¦**ï¼šçº¿æ€§å½±å“å‚æ•°é‡å’Œè®¡ç®—æ—¶é—´<br>**è¿‡æ‹Ÿåˆé£é™©**ï¼šè¿‡å¤§å¯èƒ½å¯¼è‡´è®­ç»ƒè¿‡æ‹Ÿåˆ | 128-512èŒƒå›´å†…è°ƒä¼˜<br>ç»“åˆdropouté˜²è¿‡æ‹Ÿåˆ |
| `dia_layers`  | 2      | GRUå †å å±‚æ•°    | **æŠ½è±¡å±‚æ¬¡**ï¼šå¤šå±‚æä¾›æ›´æ·±å±‚æ¬¡çš„ç‰¹å¾æŠ½è±¡<br>**æ¢¯åº¦ä¼ æ’­**ï¼šè¿‡æ·±å¯èƒ½å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±<br>**è®­ç»ƒç¨³å®šæ€§**ï¼šå±‚æ•°é€‚ä¸­ä¿è¯è®­ç»ƒç¨³å®š | 1-4å±‚ä¸ºå®œ<br>é…åˆæ¢¯åº¦è£å‰ªä½¿ç”¨            |
| `utt_insize`  | 768    | HuBERTè¾“å‡ºç»´åº¦ | **ç‰¹å¾ä¸°å¯Œåº¦**ï¼šå›ºå®šå€¼ï¼Œç”±é¢„è®­ç»ƒæ¨¡å‹å†³å®š<br>**åŒ¹é…è¦æ±‚**ï¼šå¿…é¡»ä¸HuBERTè¾“å‡ºç»´åº¦ä¸€è‡´ | ä¸å¯è°ƒæ•´<br>ç”±é¢„è®­ç»ƒæ¨¡å‹å†³å®š             |
| `out_class`   | 4      | æƒ…æ„Ÿç±»åˆ«æ•°é‡   | **ä»»åŠ¡å¤æ‚åº¦**ï¼šç±»åˆ«æ•°ç›´æ¥å½±å“åˆ†ç±»éš¾åº¦<br>**æ•°æ®å¹³è¡¡**ï¼šéœ€è¦å„ç±»åˆ«æ ·æœ¬ç›¸å¯¹å¹³è¡¡ | æ ¹æ®å…·ä½“ä»»åŠ¡ç¡®å®š<br>è€ƒè™‘ç±»åˆ«å¹³è¡¡ç­–ç•¥     |

### 4.2 è®­ç»ƒè¶…å‚æ•°æ·±åº¦åˆ†æ

| å‚æ•°å          | é»˜è®¤å€¼ | å‚æ•°å«ä¹‰       | æ€§èƒ½å½±å“æœºåˆ¶                                                 | è°ƒä¼˜ç­–ç•¥                              |
| --------------- | ------ | -------------- | ------------------------------------------------------------ | ------------------------------------- |
| `learning_rate` | 1e-5   | å­¦ä¹ ç‡         | **æ”¶æ•›é€Ÿåº¦**ï¼šè¿‡å¤§æ˜“éœ‡è¡ï¼Œè¿‡å°æ”¶æ•›æ…¢<br>**æœ€ç»ˆæ€§èƒ½**ï¼šå½±å“æ¨¡å‹æ”¶æ•›åˆ°çš„å±€éƒ¨æœ€ä¼˜è§£<br>**è®­ç»ƒç¨³å®šæ€§**ï¼šé€‚å½“å­¦ä¹ ç‡ä¿è¯è®­ç»ƒç¨³å®š | 1e-6åˆ°1e-4èŒƒå›´<br>ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦      |
| `dropout`       | 0.2    | éšæœºå¤±æ´»æ¦‚ç‡   | **æ­£åˆ™åŒ–å¼ºåº¦**ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆçš„å…³é”®å‚æ•°<br>**æ¨¡å‹å®¹é‡**ï¼šè¿‡å¤§å½±å“æ¨¡å‹è¡¨è¾¾èƒ½åŠ›<br>**æ³›åŒ–èƒ½åŠ›**ï¼šé€‚å½“dropoutæå‡æ³›åŒ–æ€§èƒ½ | 0.1-0.5èŒƒå›´è°ƒä¼˜<br>æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´ |
| `batch_size`    | 32     | æ‰¹æ¬¡å¤§å°       | **æ¢¯åº¦ä¼°è®¡**ï¼šå½±å“æ¢¯åº¦ä¼°è®¡çš„å‡†ç¡®æ€§<br>**å†…å­˜å ç”¨**ï¼šç›´æ¥å½±å“GPUå†…å­˜éœ€æ±‚<br>**è®­ç»ƒé€Ÿåº¦**ï¼šå½±å“æ¯ä¸ªepochçš„è®­ç»ƒæ—¶é—´ | 16-64æ ¹æ®æ˜¾å­˜è°ƒæ•´<br>è€ƒè™‘æ¢¯åº¦ç´¯ç§¯     |
| `attention`     | True   | æ³¨æ„åŠ›æœºåˆ¶å¼€å…³ | **é•¿åºåˆ—å»ºæ¨¡**ï¼šæå‡é•¿è·ç¦»ä¾èµ–æ•è·èƒ½åŠ›<br>**è®¡ç®—å¼€é”€**ï¼šå¢åŠ çº¦20%çš„è®¡ç®—æ—¶é—´<br>**æ¨¡å‹å¤æ‚åº¦**ï¼šå¢åŠ æ¨¡å‹å‚æ•°é‡ | æ ¹æ®åºåˆ—é•¿åº¦å†³å®š<br>çŸ­åºåˆ—å¯å…³é—­      |

### 4.3 æ•°æ®å¤„ç†å‚æ•°æ·±åº¦åˆ†æ

| å‚æ•°å         | é»˜è®¤å€¼ | å‚æ•°å«ä¹‰     | æ€§èƒ½å½±å“æœºåˆ¶                                                 | è®¾è®¡è€ƒé‡                       |
| -------------- | ------ | ------------ | ------------------------------------------------------------ | ------------------------------ |
| `time_seconds` | 3      | éŸ³é¢‘å›ºå®šé•¿åº¦ | **ä¿¡æ¯å®Œæ•´æ€§**ï¼šæ—¶é•¿å½±å“æƒ…æ„Ÿä¿¡æ¯çš„å®Œæ•´æ€§<br>**è®¡ç®—æ•ˆç‡**ï¼šé•¿åº¦ç›´æ¥å½±å“è®¡ç®—å¤æ‚åº¦<br>**å†…å­˜å ç”¨**ï¼šå½±å“æ‰¹å¤„ç†çš„å†…å­˜éœ€æ±‚ | 2-5ç§’èŒƒå›´å†…<br>å¹³è¡¡ä¿¡æ¯ä¸æ•ˆç‡  |
| `sample_rate`  | 16000  | éŸ³é¢‘é‡‡æ ·ç‡   | **é¢‘ç‡åˆ†è¾¨ç‡**ï¼šå½±å“é«˜é¢‘ä¿¡æ¯çš„ä¿ç•™<br>**å…¼å®¹æ€§**ï¼šéœ€åŒ¹é…é¢„è®­ç»ƒæ¨¡å‹è¦æ±‚<br>**æ•°æ®å¤§å°**ï¼šå½±å“éŸ³é¢‘æ•°æ®çš„å­˜å‚¨ç©ºé—´ | å›ºå®š16kHz<br>åŒ¹é…HuBERTè¦æ±‚    |
| `num_folds`    | 5      | äº¤å‰éªŒè¯æŠ˜æ•° | **è¯„ä¼°å¯é æ€§**ï¼šæŠ˜æ•°è¶Šå¤šè¯„ä¼°è¶Šå¯é <br>**è®¡ç®—æˆæœ¬**ï¼šæŠ˜æ•°å½±å“æ€»è®­ç»ƒæ—¶é—´<br>**ç»Ÿè®¡æ˜¾è‘—æ€§**ï¼šå½±å“ç»“æœçš„ç»Ÿè®¡æ„ä¹‰ | 5-10æŠ˜ä¸ºå®œ<br>å¹³è¡¡å¯é æ€§ä¸æˆæœ¬ |

### 4.4 å‚æ•°è°ƒä¼˜çš„ç³»ç»Ÿæ€§æ–¹æ³•

**å±‚æ¬¡åŒ–è°ƒä¼˜ç­–ç•¥**ï¼š

1. **æ¶æ„å‚æ•°**ï¼šå…ˆç¡®å®šhidden_sizeå’Œdia_layers
2. **è®­ç»ƒå‚æ•°**ï¼šå†è°ƒä¼˜learning_rateå’Œdropout
3. **æ•°æ®å‚æ•°**ï¼šæœ€åä¼˜åŒ–batch_sizeå’Œtime_seconds

**æ€§èƒ½ç›‘æ§æŒ‡æ ‡**ï¼š

- **è®­ç»ƒæŒ‡æ ‡**ï¼šæŸå¤±å‡½æ•°æ”¶æ•›æ›²çº¿ã€æ¢¯åº¦èŒƒæ•°
- **éªŒè¯æŒ‡æ ‡**ï¼šå‡†ç¡®ç‡ã€F1åˆ†æ•°ã€æ··æ·†çŸ©é˜µ
- **æ•ˆç‡æŒ‡æ ‡**ï¼šè®­ç»ƒæ—¶é—´ã€å†…å­˜å ç”¨ã€æ¨ç†é€Ÿåº¦

---

## 5. æ¨¡å‹å·¥ä½œæœºåˆ¶æ·±å…¥ç†è§£

### 5.1 è‡ªç›‘ç£é¢„è®­ç»ƒçš„æ·±å±‚ä»·å€¼

HuBERTæ¨¡å‹çš„é¢„è®­ç»ƒæœºåˆ¶ä½“ç°äº†ç°ä»£è¯­éŸ³å¤„ç†çš„æ ¸å¿ƒæ€æƒ³ï¼š

**æ©ç é¢„æµ‹ä»»åŠ¡çš„è®¾è®¡æ™ºæ…§**ï¼š

```python
# HuBERTé¢„è®­ç»ƒä¼ªä»£ç ç¤ºä¾‹
masked_features = mask_features(input_features, mask_prob=0.15)
predicted_features = hubert_model(masked_features)
loss = mse_loss(predicted_features, target_features)
```

**å¤šå±‚æ¬¡ç‰¹å¾å­¦ä¹ æœºåˆ¶**ï¼š

- **å£°å­¦å±‚é¢**ï¼šåº•å±‚Transformerå±‚å­¦ä¹ éŸ³ç´ ã€éŸ³è°ƒã€è¯­é€Ÿç­‰åŸºç¡€å£°å­¦ç‰¹å¾
- **è¯­è¨€å±‚é¢**ï¼šä¸­å±‚å­¦ä¹ è¯æ±‡è¾¹ç•Œã€è¯­æ³•ç»“æ„ã€è¯­ä¹‰å…³ç³»
- **éŸµå¾‹å±‚é¢**ï¼šé«˜å±‚æ•è·èŠ‚å¥ã€é‡éŸ³ã€è¯­è°ƒå˜åŒ–ï¼Œè¿™äº›ç‰¹å¾ä¸æƒ…æ„Ÿè¡¨è¾¾å¯†åˆ‡ç›¸å…³

**è¿ç§»å­¦ä¹ çš„æœ‰æ•ˆæ€§**ï¼š

- é¢„è®­ç»ƒç‰¹å¾åŒ…å«ä¸°å¯Œçš„è¯­éŸ³é€šç”¨è¡¨ç¤º
- åœ¨æƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸Šå¾®è°ƒæ—¶ï¼Œæ¨¡å‹èƒ½å¿«é€Ÿé€‚åº”ç‰¹å®šé¢†åŸŸç‰¹å¾
- ç›¸æ¯”ä»é›¶è®­ç»ƒï¼Œæ˜¾è‘—å‡å°‘äº†æ‰€éœ€çš„æ ‡æ³¨æ•°æ®é‡

### 5.2 åºåˆ—å»ºæ¨¡çš„æ—¶åºä¾èµ–æœºåˆ¶

åŒå‘GRUçš„é—¨æ§æœºåˆ¶å®ç°äº†å¯¹æ—¶åºä¿¡æ¯çš„ç²¾ç¡®æ§åˆ¶ï¼š

**é—¨æ§æœºåˆ¶çš„æ•°å­¦è¡¨è¾¾**ï¼š

```python
# GRUé—¨æ§æœºåˆ¶ä¼ªä»£ç 
reset_gate = sigmoid(W_r @ [h_prev, x_t])
update_gate = sigmoid(W_u @ [h_prev, x_t])
candidate_h = tanh(W_h @ [reset_gate * h_prev, x_t])
h_t = (1 - update_gate) * h_prev + update_gate * candidate_h
```

**åŒå‘ä¿¡æ¯èåˆçš„ä¼˜åŠ¿**ï¼š

- **å‰å‘æµ**ï¼šæ•è·ä»è¯­éŸ³å¼€å§‹åˆ°å½“å‰ä½ç½®çš„æƒ…æ„Ÿå‘å±•è¶‹åŠ¿
- **åå‘æµ**ï¼šåˆ©ç”¨æœªæ¥ä¿¡æ¯ä¸ºå½“å‰åˆ¤æ–­æä¾›ä¸Šä¸‹æ–‡çº¦æŸ
- **ä¿¡æ¯äº’è¡¥**ï¼šå‰åå‘ä¿¡æ¯çš„ç»“åˆæä¾›äº†æ›´å…¨é¢çš„æ—¶åºè¡¨ç¤º

**æƒ…æ„Ÿæ—¶åºæ¨¡å¼çš„å»ºæ¨¡**ï¼š

- **æƒ…æ„Ÿèµ·ä¼**ï¼šGRUèƒ½å¤Ÿè®°å¿†æƒ…æ„Ÿçš„å˜åŒ–è½¨è¿¹
- **å…³é”®è½¬æŠ˜**ï¼šé—¨æ§æœºåˆ¶è‡ªåŠ¨è¯†åˆ«æƒ…æ„Ÿè¡¨è¾¾çš„é‡è¦æ—¶åˆ»
- **ä¸Šä¸‹æ–‡ä¾èµ–**ï¼šåŒå‘è®¾è®¡ç¡®ä¿æ¯ä¸ªæ—¶åˆ»éƒ½èƒ½è·å¾—å……åˆ†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯

### 5.3 æ³¨æ„åŠ›æœºåˆ¶çš„åŠ¨æ€èšç„¦åŸç†

æ³¨æ„åŠ›æœºåˆ¶å®ç°äº†å¯¹åºåˆ—ä¿¡æ¯çš„æ™ºèƒ½é€‰æ‹©ï¼š

**æ³¨æ„åŠ›æƒé‡çš„å­¦ä¹ æœºåˆ¶**ï¼š

```python
# æ³¨æ„åŠ›æƒé‡è®¡ç®—çš„æ ¸å¿ƒé€»è¾‘
similarity_scores = query @ keys.T  # è®¡ç®—ç›¸ä¼¼åº¦
attention_weights = softmax(similarity_scores)  # å½’ä¸€åŒ–æƒé‡
attended_features = attention_weights @ values  # åŠ æƒèšåˆ
```

**åŠ¨æ€èšç„¦çš„å®ç°åŸç†**ï¼š

- **æŸ¥è¯¢é©±åŠ¨**ï¼šæ¯ä¸ªæ—¶é—´æ­¥ä½œä¸ºæŸ¥è¯¢ï¼ŒåŠ¨æ€å…³æ³¨æ•´ä¸ªåºåˆ—
- **ç›¸ä¼¼åº¦åŒ¹é…**ï¼šå­¦ä¹ åˆ°çš„å˜æ¢çŸ©é˜µæ•è·æŸ¥è¯¢ä¸é”®çš„åŒ¹é…æ¨¡å¼
- **è‡ªé€‚åº”æƒé‡**ï¼šä¸åŒæƒ…æ„Ÿç±»åˆ«ä¸‹çš„æ³¨æ„åŠ›æ¨¡å¼è‡ªåŠ¨åˆ†åŒ–

**æƒ…æ„Ÿå…³é”®ä¿¡æ¯çš„è¯†åˆ«**ï¼š

- **éŸµå¾‹é‡ç‚¹**ï¼šè‡ªåŠ¨å…³æ³¨è¯­è°ƒå˜åŒ–å‰§çƒˆçš„æ—¶é—´æ®µ
- **è¯­ä¹‰å…³é”®è¯**ï¼šèšç„¦äºå¸¦æœ‰å¼ºæƒ…æ„Ÿè‰²å½©çš„è¯æ±‡
- **åœé¡¿æ¨¡å¼**ï¼šè¯†åˆ«æƒ…æ„Ÿè¡¨è¾¾ä¸­çš„åœé¡¿å’ŒèŠ‚å¥å˜åŒ–

### 5.4 å…¨å±€æ± åŒ–çš„ä¿¡æ¯èšåˆç­–ç•¥

æœ€å¤§æ± åŒ–æ“ä½œå®ç°äº†ä»åºåˆ—åˆ°å…¨å±€ç‰¹å¾çš„è½¬æ¢ï¼š

**æœ€å¤§æ± åŒ–çš„é€‰æ‹©rationale**ï¼š

```python
# æœ€å¤§æ± åŒ– vs å¹³å‡æ± åŒ–çš„å¯¹æ¯”
max_pooled = F.max_pool1d(features, kernel_size=seq_len)  # ä¿ç•™æœ€å¼ºä¿¡å·
avg_pooled = F.avg_pool1d(features, kernel_size=seq_len)  # å¹³å‡æ‰€æœ‰ä¿¡å·
```

**æƒ…æ„Ÿè¯†åˆ«ä¸­çš„ä¼˜åŠ¿**ï¼š

- **æ˜¾è‘—æ€§ä¿ç•™**ï¼šæœ€å¤§æ± åŒ–ä¿ç•™æœ€å¼ºçš„æƒ…æ„Ÿæ¿€æ´»ä¿¡å·
- **å™ªå£°æŠ‘åˆ¶**ï¼šå¿½ç•¥å¼±æ¿€æ´»çš„å™ªå£°ä¿¡æ¯
- **ä¸å˜æ€§**ï¼šå¯¹åºåˆ—é•¿åº¦å˜åŒ–å…·æœ‰ä¸€å®šçš„é²æ£’æ€§

---

## 6. ç³»ç»Ÿä¼˜åŠ¿ä¸æŠ€æœ¯åˆ›æ–°

### 6.1 ç«¯åˆ°ç«¯å­¦ä¹ èŒƒå¼çš„æŠ€æœ¯çªç ´

**ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§**ï¼š

- æ‰‹å·¥ç‰¹å¾è®¾è®¡ä¾èµ–é¢†åŸŸä¸“å®¶çŸ¥è¯†
- ç‰¹å¾æå–ä¸åˆ†ç±»å™¨åˆ†ç¦»è®­ç»ƒï¼Œæ— æ³•å®ç°å…¨å±€ä¼˜åŒ–
- ç‰¹å¾è¡¨è¾¾èƒ½åŠ›å—é™äºäººå·¥è®¾è®¡çš„æƒ³è±¡åŠ›

**ç«¯åˆ°ç«¯å­¦ä¹ çš„ä¼˜åŠ¿**ï¼š

- **è‡ªåŠ¨ç‰¹å¾å­¦ä¹ **ï¼šæ¨¡å‹è‡ªåŠ¨å‘ç°æœ€ä¼˜çš„ç‰¹å¾è¡¨ç¤º
- **å…¨å±€ä¼˜åŒ–**ï¼šä»åŸå§‹è¾“å…¥åˆ°æœ€ç»ˆè¾“å‡ºçš„è”åˆä¼˜åŒ–
- **é€‚åº”æ€§å¼º**ï¼šèƒ½å¤Ÿé€‚åº”ä¸åŒçš„æ•°æ®åˆ†å¸ƒå’Œä»»åŠ¡éœ€æ±‚

### 6.2 å¤šå±‚æ¬¡ç‰¹å¾èåˆçš„åˆ›æ–°è®¾è®¡

**ç‰¹å¾èåˆçš„å±‚æ¬¡ç»“æ„**ï¼š

```
HuBERTç‰¹å¾(768ç»´) â†’ GRUæ—¶åºå»ºæ¨¡(512ç»´) â†’ æ³¨æ„åŠ›å¢å¼º â†’ å…¨å±€æ± åŒ– â†’ åˆ†ç±»è¾“å‡º
```

**èåˆæœºåˆ¶çš„æŠ€æœ¯åˆ›æ–°**ï¼š

- **è¯­ä¹‰-æ—¶åºèåˆ**ï¼šHuBERTçš„è¯­ä¹‰ç‰¹å¾ä¸GRUçš„æ—¶åºå»ºæ¨¡ç›¸ç»“åˆ
- **å±€éƒ¨-å…¨å±€èåˆ**ï¼šæ³¨æ„åŠ›æœºåˆ¶å®ç°å±€éƒ¨ç‰¹å¾ä¸å…¨å±€ä¸Šä¸‹æ–‡çš„èåˆ
- **é™æ€-åŠ¨æ€èåˆ**ï¼šé™æ€çš„é¢„è®­ç»ƒç‰¹å¾ä¸åŠ¨æ€çš„åºåˆ—å»ºæ¨¡ç›¸ç»“åˆ

### 6.3 æ³¨æ„åŠ›å¢å¼ºæœºåˆ¶çš„åŸåˆ›æ€§åº”ç”¨

**æ³¨æ„åŠ›æœºåˆ¶åœ¨è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ä¸­çš„åˆ›æ–°åº”ç”¨**ï¼š

- **æ—¶åºæ³¨æ„åŠ›**ï¼šé’ˆå¯¹è¯­éŸ³çš„æ—¶åºç‰¹æ€§è®¾è®¡çš„æ³¨æ„åŠ›æœºåˆ¶
- **æƒ…æ„Ÿèšç„¦**ï¼šè‡ªåŠ¨è¯†åˆ«æƒ…æ„Ÿè¡¨è¾¾çš„å…³é”®æ—¶é—´æ®µ
- **å¯è§£é‡Šæ€§**ï¼šæ³¨æ„åŠ›æƒé‡æä¾›æ¨¡å‹å†³ç­–çš„å¯è§†åŒ–è§£é‡Š

### 6.4 å·¥ç¨‹åŒ–éƒ¨ç½²çš„å…¨é¢è€ƒè™‘

**ç³»ç»Ÿå·¥ç¨‹åŒ–çš„å®Œæ•´æ€§**ï¼š

- **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¸…æ™°çš„ä»£ç ç»“æ„ä¾¿äºç»´æŠ¤å’Œæ‰©å±•
- **å®æ—¶å¤„ç†èƒ½åŠ›**ï¼šæ”¯æŒéº¦å…‹é£å®æ—¶å½•éŸ³å’Œæƒ…æ„Ÿè¯†åˆ«
- **ç”¨æˆ·å‹å¥½ç•Œé¢**ï¼šå®Œæ•´çš„PyQt5å›¾å½¢ç•Œé¢
- **è·¨å¹³å°å…¼å®¹**ï¼šæ”¯æŒä¸åŒæ“ä½œç³»ç»Ÿçš„éƒ¨ç½²

**éƒ¨ç½²ä¼˜åŒ–çš„æŠ€æœ¯ç»†èŠ‚**ï¼š

- **æ¨¡å‹å‹ç¼©**ï¼šé€šè¿‡é‡åŒ–ç­‰æŠ€æœ¯å‡å°‘æ¨¡å‹å¤§å°
- **æ¨ç†åŠ é€Ÿ**ï¼šGPUåŠ é€Ÿå’Œæ‰¹å¤„ç†ä¼˜åŒ–
- **å†…å­˜ç®¡ç†**ï¼šé«˜æ•ˆçš„éŸ³é¢‘ç¼“å†²å’Œç‰¹å¾ç¼“å­˜æœºåˆ¶

### 6.5 è¯„ä¼°æ–¹æ³•çš„ç§‘å­¦æ€§

**5æŠ˜äº¤å‰éªŒè¯çš„ç»Ÿè®¡ä¸¥è°¨æ€§**ï¼š

- ç¡®ä¿ç»“æœçš„ç»Ÿè®¡æ˜¾è‘—æ€§å’Œå¯é‡ç°æ€§
- é¿å…æ•°æ®åˆ’åˆ†å¶ç„¶æ€§å¯¹ç»“æœçš„å½±å“
- æä¾›æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å¯é ä¼°è®¡

**å¤šæŒ‡æ ‡è¯„ä¼°çš„å…¨é¢æ€§**ï¼š

- å‡†ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°çš„ç»¼åˆè¯„ä¼°
- æ··æ·†çŸ©é˜µåˆ†æå„ç±»åˆ«çš„è¯†åˆ«æ€§èƒ½
- ç»Ÿè®¡æ£€éªŒç¡®ä¿ç»“æœçš„ç§‘å­¦æ€§

---

## æ€»ç»“

è¯¥IEMOCAPè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿå±•ç°äº†ç°ä»£æ·±åº¦å­¦ä¹ åœ¨è¯­éŸ³å¤„ç†é¢†åŸŸçš„å…ˆè¿›æŠ€æœ¯åº”ç”¨ã€‚é€šè¿‡HuBERTé¢„è®­ç»ƒæ¨¡å‹çš„å¼ºå¤§ç‰¹å¾æå–èƒ½åŠ›ã€åŒå‘GRUçš„ç²¾ç¡®æ—¶åºå»ºæ¨¡ã€æ³¨æ„åŠ›æœºåˆ¶çš„æ™ºèƒ½èšç„¦ï¼Œä»¥åŠå…¨å±€æ± åŒ–çš„æœ‰æ•ˆä¿¡æ¯èšåˆï¼Œç³»ç»Ÿå®ç°äº†ä»åŸå§‹éŸ³é¢‘åˆ°æƒ…æ„Ÿç±»åˆ«çš„ç«¯åˆ°ç«¯å­¦ä¹ ã€‚

ç³»ç»Ÿçš„æŠ€æœ¯åˆ›æ–°ä½“ç°åœ¨å¤šä¸ªæ–¹é¢ï¼šè‡ªç›‘ç£é¢„è®­ç»ƒä¸ä¸‹æ¸¸ä»»åŠ¡çš„æœ‰æ•ˆç»“åˆã€å¤šå±‚æ¬¡ç‰¹å¾çš„æ·±åº¦èåˆã€æ³¨æ„åŠ›æœºåˆ¶çš„åŸåˆ›æ€§åº”ç”¨ï¼Œä»¥åŠå·¥ç¨‹åŒ–éƒ¨ç½²çš„å…¨é¢è€ƒè™‘ã€‚è¿™äº›è®¾è®¡ä¸ä»…ä¿è¯äº†æ¨¡å‹çš„é«˜æ€§èƒ½ï¼Œä¹Ÿä¸ºå®é™…åº”ç”¨æä¾›äº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚

é€šè¿‡æ·±å…¥çš„æºç åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¯¥ç³»ç»Ÿä¸ä»…æ˜¯ä¸€ä¸ªæŠ€æœ¯å®ç°ï¼Œæ›´æ˜¯å¯¹è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«é¢†åŸŸå‰æ²¿æŠ€æœ¯çš„ç³»ç»Ÿæ€§æ•´åˆå’Œåˆ›æ–°æ€§åº”ç”¨ã€‚å®ƒä¸ºç›¸å…³ç ”ç©¶å’Œåº”ç”¨å¼€å‘æä¾›äº†å®è´µçš„å‚è€ƒå’Œå€Ÿé‰´ä»·å€¼ã€‚

