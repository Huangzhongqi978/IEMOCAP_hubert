#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„IEMOCAPè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«è®­ç»ƒä»£ç 
ä¸“æ³¨äºè·¨è¯´è¯äººæ³›åŒ–å’Œé«˜å‡†ç¡®ç‡ä¼˜åŒ–

ä¸»è¦æ”¹è¿›:
1. è¯´è¯äººæ— å…³è®­ç»ƒç­–ç•¥
2. å¢å¼ºçš„GRUæ¶æ„ + è¯´è¯äººå½’ä¸€åŒ–
3. å¯¹æŠ—è®­ç»ƒå‡å°‘è¯´è¯äººåè§
4. å…ˆè¿›çš„è®­ç»ƒç­–ç•¥å’Œæ•°æ®å¢å¼º
5. å…¨é¢çš„å¯è§†åŒ–å’Œè¯„ä¼°
"""

import argparse
import pickle
import copy
import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau
from torch.utils.data import DataLoader
import numpy as np
import pandas as pd
import os
import json
import warnings
from datetime import datetime
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    confusion_matrix, classification_report, 
    accuracy_score, f1_score, precision_score, recall_score
)
from sklearn.manifold import TSNE
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
matplotlib.rcParams['axes.unicode_minus'] = False
matplotlib.rcParams['figure.dpi'] = 100
matplotlib.rcParams['savefig.dpi'] = 300

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from models.enhanced_gru import create_enhanced_model
from utils.speaker_independent_data import SpeakerIndependentDataLoader, collate_fn

warnings.filterwarnings('ignore')

# è§£å†³ä¸­æ–‡ç¼–ç é—®é¢˜
import locale
try:
    locale.setlocale(locale.LC_ALL, 'zh_CN.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'Chinese_China.UTF-8')
    except:
        print("âš ï¸ æ— æ³•è®¾ç½®ä¸­æ–‡æœ¬åœ°åŒ–ï¼Œå¯èƒ½å½±å“ä¸­æ–‡æ˜¾ç¤º")

class AdvancedTrainer:
    """é«˜çº§è®­ç»ƒå™¨ - åŒ…å«æ‰€æœ‰ä¼˜åŒ–ç­–ç•¥"""
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device('cuda' if torch.cuda.is_available() and args.cuda else 'cpu')
        
        # æƒ…æ„Ÿæ ‡ç­¾
        self.emotion_labels = {0: 'Angry', 1: 'Happy', 2: 'Neutral', 3: 'Sad'}
        self.emotion_colors = ['#e74c3c', '#f1c40f', '#95a5a6', '#3498db']
        
        # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        self.data_loader = SpeakerIndependentDataLoader(args.data_path)
        
        # åˆ›å»ºå®éªŒç›®å½•
        self.exp_name = f"enhanced_emotion_recognition_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.exp_dir = os.path.join('experiments', self.exp_name)
        self.plots_dir = os.path.join(self.exp_dir, 'plots')
        self.models_dir = os.path.join(self.exp_dir, 'models')
        
        os.makedirs(self.exp_dir, exist_ok=True)
        os.makedirs(self.plots_dir, exist_ok=True)
        os.makedirs(self.models_dir, exist_ok=True)
        
        # ä¿å­˜é…ç½®
        self.save_config()
        
        # è®­ç»ƒå†å²è®°å½•
        self.training_history = {
            'fold_results': [],
            'best_metrics': {
                'accuracy': 0.0,
                'f1_score': 0.0,
                'fold': -1
            }
        }
        
        print(f"ğŸš€ å¢å¼ºè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ å®éªŒç›®å½•: {self.exp_dir}")
        print(f"ğŸ–¥ï¸  è®¾å¤‡: {self.device}")
    
    def save_config(self):
        """ä¿å­˜å®éªŒé…ç½®"""
        config = {
            'args': vars(self.args),
            'exp_name': self.exp_name,
            'timestamp': datetime.now().isoformat(),
            'device': str(self.device)
        }
        
        config_path = os.path.join(self.exp_dir, 'config.json')
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def create_model(self):
        """åˆ›å»ºå¢å¼ºæ¨¡å‹"""
        model = create_enhanced_model(self.args)
        model = model.to(self.device)
        
        # è®¡ç®—å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
        print(f"   æ€»å‚æ•°: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        return model
    
    def create_optimizers_and_schedulers(self, model):
        """åˆ›å»ºä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        # åˆ†ç»„å‚æ•° - ä¸åŒç»„ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡
        hubert_params = []
        gru_params = []
        classifier_params = []
        
        for name, param in model.named_parameters():
            if not param.requires_grad:
                continue
                
            if 'feature_extractor' in name:
                hubert_params.append(param)
            elif 'utterance_net' in name:
                gru_params.append(param)
            else:
                classifier_params.append(param)
        
        # åˆ›å»ºå‚æ•°ç»„
        param_groups = [
            {'params': hubert_params, 'lr': self.args.lr * 0.1, 'name': 'hubert'},  # HuBERTç”¨æ›´å°å­¦ä¹ ç‡
            {'params': gru_params, 'lr': self.args.lr, 'name': 'gru'},
            {'params': classifier_params, 'lr': self.args.lr * 2, 'name': 'classifier'}  # åˆ†ç±»å™¨ç”¨æ›´å¤§å­¦ä¹ ç‡
        ]
        
        # ä¸»ä¼˜åŒ–å™¨
        optimizer = optim.AdamW(
            param_groups,
            weight_decay=self.args.weight_decay,
            betas=(0.9, 0.999),
            eps=1e-8
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = CosineAnnealingWarmRestarts(
            optimizer, 
            T_0=self.args.T_0,
            T_mult=2,
            eta_min=1e-7
        )
        
        # å¤‡ç”¨è°ƒåº¦å™¨ - åŸºäºéªŒè¯æŸå¤±çš„è‡ªé€‚åº”è°ƒåº¦
        plateau_scheduler = ReduceLROnPlateau(
            optimizer, 
            mode='min',
            factor=0.5,
            patience=5,
            verbose=True,
            min_lr=1e-7
        )
        
        return optimizer, scheduler, plateau_scheduler
    
    def compute_loss(self, model_outputs, targets, speaker_targets, alpha=1.0):
        """è®¡ç®—ç»¼åˆæŸå¤±"""
        emotion_logits = model_outputs['emotion_logits']
        speaker_logits = model_outputs['speaker_logits']
        
        # æƒ…æ„Ÿåˆ†ç±»æŸå¤±ï¼ˆä¸»è¦ä»»åŠ¡ï¼‰
        emotion_loss = F.cross_entropy(emotion_logits, targets)
        
        total_loss = emotion_loss
        loss_dict = {'emotion_loss': emotion_loss.item()}
        
        # è¯´è¯äººå¯¹æŠ—æŸå¤±
        if speaker_logits is not None and self.args.speaker_adversarial:
            speaker_loss = F.cross_entropy(speaker_logits, speaker_targets)
            total_loss += self.args.adversarial_weight * speaker_loss
            loss_dict['speaker_loss'] = speaker_loss.item()
        
        # æ­£åˆ™åŒ–æŸå¤±
        if self.args.l2_reg > 0:
            l2_loss = sum(torch.norm(p, 2) for p in model_outputs.get('regularization_params', []))
            total_loss += self.args.l2_reg * l2_loss
            loss_dict['l2_loss'] = l2_loss.item() if isinstance(l2_loss, torch.Tensor) else l2_loss
        
        loss_dict['total_loss'] = total_loss.item()
        return total_loss, loss_dict
    
    def train_epoch(self, model, train_loader, optimizer, scheduler, epoch, alpha):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        model.train()
        
        total_loss = 0.0
        total_emotion_loss = 0.0
        total_speaker_loss = 0.0
        correct_predictions = 0
        total_samples = 0
        
        all_predictions = []
        all_targets = []
        
        for batch_idx, batch in enumerate(train_loader):
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            audio_features = batch['audio_features'].to(self.device)
            emotion_targets = batch['emotion_labels'].to(self.device)
            speaker_targets = batch['speaker_labels'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            outputs = model(audio_features, alpha=alpha)
            
            # è®¡ç®—æŸå¤±
            loss, loss_dict = self.compute_loss(outputs, emotion_targets, speaker_targets, alpha)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), self.args.max_grad_norm)
            
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss_dict['total_loss']
            total_emotion_loss += loss_dict['emotion_loss']
            if 'speaker_loss' in loss_dict:
                total_speaker_loss += loss_dict['speaker_loss']
            
            # è®¡ç®—å‡†ç¡®ç‡
            predictions = torch.argmax(outputs['emotion_logits'], dim=1)
            correct_predictions += (predictions == emotion_targets).sum().item()
            total_samples += emotion_targets.size(0)
            
            all_predictions.extend(predictions.cpu().numpy())
            all_targets.extend(emotion_targets.cpu().numpy())
            
            # æ‰“å°è¿›åº¦
            if batch_idx % self.args.log_interval == 0:
                print(f'è®­ç»ƒ Epoch: {epoch} [{batch_idx * len(audio_features)}/{len(train_loader.dataset)} '
                      f'({100. * batch_idx / len(train_loader):.0f}%)]\\t'
                      f'æŸå¤±: {loss.item():.6f}')
        
        # è®¡ç®—epochç»Ÿè®¡
        avg_loss = total_loss / len(train_loader)
        avg_emotion_loss = total_emotion_loss / len(train_loader)
        avg_speaker_loss = total_speaker_loss / len(train_loader) if total_speaker_loss > 0 else 0
        accuracy = correct_predictions / total_samples
        f1 = f1_score(all_targets, all_predictions, average='weighted')
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        return {
            'loss': avg_loss,
            'emotion_loss': avg_emotion_loss,
            'speaker_loss': avg_speaker_loss,
            'accuracy': accuracy,
            'f1_score': f1,
            'learning_rate': optimizer.param_groups[0]['lr']
        }
    
    def evaluate(self, model, data_loader, alpha=0.0):
        """è¯„ä¼°æ¨¡å‹"""
        model.eval()
        
        total_loss = 0.0
        correct_predictions = 0
        total_samples = 0
        
        all_predictions = []
        all_targets = []
        all_speaker_predictions = []
        all_speaker_targets = []
        all_features = []
        
        with torch.no_grad():
            for batch in data_loader:
                # æ•°æ®ç§»åˆ°è®¾å¤‡
                audio_features = batch['audio_features'].to(self.device)
                emotion_targets = batch['emotion_labels'].to(self.device)
                speaker_targets = batch['speaker_labels'].to(self.device)
                
                # å‰å‘ä¼ æ’­
                outputs = model(audio_features, alpha=alpha)
                
                # è®¡ç®—æŸå¤±
                loss, _ = self.compute_loss(outputs, emotion_targets, speaker_targets, alpha)
                total_loss += loss.item()
                
                # é¢„æµ‹
                emotion_predictions = torch.argmax(outputs['emotion_logits'], dim=1)
                correct_predictions += (emotion_predictions == emotion_targets).sum().item()
                total_samples += emotion_targets.size(0)
                
                # æ”¶é›†ç»“æœ
                all_predictions.extend(emotion_predictions.cpu().numpy())
                all_targets.extend(emotion_targets.cpu().numpy())
                all_features.append(outputs['global_features'].cpu().numpy())
                
                if outputs['speaker_logits'] is not None:
                    speaker_predictions = torch.argmax(outputs['speaker_logits'], dim=1)
                    all_speaker_predictions.extend(speaker_predictions.cpu().numpy())
                    all_speaker_targets.extend(speaker_targets.cpu().numpy())
        
        # è®¡ç®—æŒ‡æ ‡
        avg_loss = total_loss / len(data_loader)
        accuracy = correct_predictions / total_samples
        f1 = f1_score(all_targets, all_predictions, average='weighted')
        precision = precision_score(all_targets, all_predictions, average='weighted')
        recall = recall_score(all_targets, all_predictions, average='weighted')
        
        # å„ç±»åˆ«F1åˆ†æ•°
        f1_per_class = f1_score(all_targets, all_predictions, average=None)
        
        # è¯´è¯äººåˆ†ç±»å‡†ç¡®ç‡ï¼ˆå¦‚æœæœ‰ï¼‰
        speaker_accuracy = 0.0
        if all_speaker_predictions:
            speaker_accuracy = accuracy_score(all_speaker_targets, all_speaker_predictions)
        
        results = {
            'loss': avg_loss,
            'accuracy': accuracy,
            'f1_score': f1,
            'precision': precision,
            'recall': recall,
            'f1_per_class': f1_per_class,
            'speaker_accuracy': speaker_accuracy,
            'predictions': all_predictions,
            'targets': all_targets,
            'features': np.vstack(all_features) if all_features else None
        }
        
        return results
    
    def train_fold(self, fold_idx):
        """è®­ç»ƒå•ä¸ªfold"""
        print(f"\\n{'='*60}")
        print(f"ğŸ”„ å¼€å§‹è®­ç»ƒç¬¬ {fold_idx+1}/{self.args.n_folds} æŠ˜")
        print(f"{'='*60}")
        
        # åˆ›å»ºæ•°æ®åˆ’åˆ†
        train_data, val_data, test_data = self.data_loader.create_speaker_independent_splits(
            fold_idx, self.args.n_folds
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_data, 
            batch_size=self.args.batch_size,
            shuffle=True,
            collate_fn=collate_fn,
            num_workers=self.args.num_workers,
            pin_memory=True,
            drop_last=True
        )
        
        val_loader = DataLoader(
            val_data,
            batch_size=self.args.batch_size,
            shuffle=False,
            collate_fn=collate_fn,
            num_workers=self.args.num_workers,
            pin_memory=True
        )
        
        test_loader = DataLoader(
            test_data,
            batch_size=self.args.batch_size,
            shuffle=False,
            collate_fn=collate_fn,
            num_workers=self.args.num_workers,
            pin_memory=True
        )
        
        # åˆ›å»ºæ¨¡å‹
        model = self.create_model()
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer, scheduler, plateau_scheduler = self.create_optimizers_and_schedulers(model)
        
        # è®­ç»ƒå†å²
        fold_history = {
            'train_loss': [], 'train_acc': [], 'train_f1': [],
            'val_loss': [], 'val_acc': [], 'val_f1': [],
            'learning_rates': []
        }
        
        best_val_f1 = 0.0
        best_model_state = None
        patience_counter = 0
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(1, self.args.epochs + 1):
            # è®¡ç®—å¯¹æŠ—è®­ç»ƒå¼ºåº¦
            alpha = min(1.0, epoch / self.args.adversarial_warmup) if self.args.speaker_adversarial else 0.0
            
            # è®­ç»ƒ
            train_results = self.train_epoch(model, train_loader, optimizer, scheduler, epoch, alpha)
            
            # éªŒè¯
            val_results = self.evaluate(model, val_loader, alpha=0.0)
            
            # è®°å½•å†å²
            fold_history['train_loss'].append(train_results['loss'])
            fold_history['train_acc'].append(train_results['accuracy'])
            fold_history['train_f1'].append(train_results['f1_score'])
            fold_history['val_loss'].append(val_results['loss'])
            fold_history['val_acc'].append(val_results['accuracy'])
            fold_history['val_f1'].append(val_results['f1_score'])
            fold_history['learning_rates'].append(train_results['learning_rate'])
            
            # æ›´æ–°plateauè°ƒåº¦å™¨
            plateau_scheduler.step(val_results['loss'])
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_results['f1_score'] > best_val_f1:
                best_val_f1 = val_results['f1_score']
                best_model_state = copy.deepcopy(model.state_dict())
                patience_counter = 0
                
                print(f"âœ… æ–°çš„æœ€ä½³éªŒè¯F1: {best_val_f1:.4f}")
            else:
                patience_counter += 1
            
            # æ—©åœ
            if patience_counter >= self.args.patience:
                print(f"â¹ï¸ æ—©åœè§¦å‘ (patience={self.args.patience})")
                break
            
            # æ‰“å°epochç»“æœ
            print(f"Epoch {epoch:3d} | "
                  f"è®­ç»ƒ: Loss={train_results['loss']:.4f}, Acc={train_results['accuracy']:.4f}, F1={train_results['f1_score']:.4f} | "
                  f"éªŒè¯: Loss={val_results['loss']:.4f}, Acc={val_results['accuracy']:.4f}, F1={val_results['f1_score']:.4f} | "
                  f"LR={train_results['learning_rate']:.2e}")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•
        model.load_state_dict(best_model_state)
        
        # æœ€ç»ˆæµ‹è¯•
        test_results = self.evaluate(model, test_loader, alpha=0.0)
        
        print(f"\\nğŸ¯ ç¬¬ {fold_idx+1} æŠ˜æœ€ç»ˆç»“æœ:")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {test_results['accuracy']:.4f}")
        print(f"   æµ‹è¯•F1åˆ†æ•°: {test_results['f1_score']:.4f}")
        print(f"   æµ‹è¯•ç²¾ç¡®ç‡: {test_results['precision']:.4f}")
        print(f"   æµ‹è¯•å¬å›ç‡: {test_results['recall']:.4f}")
        
        # ä¿å­˜æ¨¡å‹
        model_path = os.path.join(self.models_dir, f'best_model_fold_{fold_idx}.pth')
        torch.save({
            'model_state_dict': best_model_state,
            'fold_idx': fold_idx,
            'test_results': test_results,
            'args': self.args
        }, model_path)
        
        # ä¿å­˜GUIå…¼å®¹çš„.pklæ ¼å¼æ¨¡å‹
        pkl_model_path = os.path.join(self.models_dir, f'model_fold_{fold_idx}.pkl')
        model.load_state_dict(best_model_state)
        model.eval()
        torch.save(model, pkl_model_path)
        print(f"âœ… å·²ä¿å­˜GUIå…¼å®¹æ¨¡å‹: {pkl_model_path}")
        
        # ç”Ÿæˆå¯è§†åŒ–
        self.plot_fold_results(fold_idx, fold_history, test_results, test_loader, model)
        
        return {
            'fold_idx': fold_idx,
            'test_results': test_results,
            'fold_history': fold_history,
            'model_path': model_path
        }
    
    def plot_fold_results(self, fold_idx, fold_history, test_results, test_loader, model):
        """ç»˜åˆ¶å•ä¸ªfoldçš„ç»“æœ"""
        # 1. è®­ç»ƒæ›²çº¿
        self.plot_training_curves(fold_idx, fold_history)
        
        # 2. æ··æ·†çŸ©é˜µ
        self.plot_confusion_matrix(fold_idx, test_results)
        
        # 3. ç‰¹å¾å¯è§†åŒ–
        if test_results['features'] is not None:
            self.plot_feature_visualization(fold_idx, test_results)
        
        # 4. æ³¨æ„åŠ›å¯è§†åŒ–ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.args.attention:
            self.plot_attention_visualization(fold_idx, test_loader, model)
    
    def plot_training_curves(self, fold_idx, fold_history):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        epochs = range(1, len(fold_history['train_loss']) + 1)
        
        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(epochs, fold_history['train_loss'], 'b-', label='è®­ç»ƒæŸå¤±', alpha=0.8)
        axes[0, 0].plot(epochs, fold_history['val_loss'], 'r-', label='éªŒè¯æŸå¤±', alpha=0.8)
        axes[0, 0].set_title('æŸå¤±æ›²çº¿')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # å‡†ç¡®ç‡æ›²çº¿
        axes[0, 1].plot(epochs, fold_history['train_acc'], 'b-', label='è®­ç»ƒå‡†ç¡®ç‡', alpha=0.8)
        axes[0, 1].plot(epochs, fold_history['val_acc'], 'r-', label='éªŒè¯å‡†ç¡®ç‡', alpha=0.8)
        axes[0, 1].set_title('å‡†ç¡®ç‡æ›²çº¿')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # F1åˆ†æ•°æ›²çº¿
        axes[1, 0].plot(epochs, fold_history['train_f1'], 'b-', label='è®­ç»ƒF1', alpha=0.8)
        axes[1, 0].plot(epochs, fold_history['val_f1'], 'r-', label='éªŒè¯F1', alpha=0.8)
        axes[1, 0].set_title('F1åˆ†æ•°æ›²çº¿')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('F1 Score')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # å­¦ä¹ ç‡æ›²çº¿
        axes[1, 1].plot(epochs, fold_history['learning_rates'], 'g-', alpha=0.8)
        axes[1, 1].set_title('å­¦ä¹ ç‡æ›²çº¿')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Learning Rate')
        axes[1, 1].set_yscale('log')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.plots_dir, f'training_curves_fold_{fold_idx}.png'),
                   dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_confusion_matrix(self, fold_idx, test_results):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(test_results['targets'], test_results['predictions'])
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=self.emotion_labels.values(),
                   yticklabels=self.emotion_labels.values())
        plt.title(f'ç¬¬ {fold_idx+1} æŠ˜æ··æ·†çŸ©é˜µ\\nå‡†ç¡®ç‡: {test_results["accuracy"]:.4f}, F1: {test_results["f1_score"]:.4f}')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.plots_dir, f'confusion_matrix_fold_{fold_idx}.png'),
                   dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_feature_visualization(self, fold_idx, test_results):
        """ç»˜åˆ¶ç‰¹å¾å¯è§†åŒ–"""
        features = test_results['features']
        targets = test_results['targets']
        
        # t-SNEé™ç»´
        print(f"ğŸ” å¯¹ç¬¬ {fold_idx+1} æŠ˜ç‰¹å¾è¿›è¡Œt-SNEé™ç»´...")
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        features_2d = tsne.fit_transform(features)
        
        # ç»˜åˆ¶
        plt.figure(figsize=(12, 8))
        for emotion_id, emotion_name in self.emotion_labels.items():
            mask = np.array(targets) == emotion_id
            plt.scatter(features_2d[mask, 0], features_2d[mask, 1], 
                       c=self.emotion_colors[emotion_id], label=emotion_name, 
                       alpha=0.7, s=50)
        
        plt.title(f'ç¬¬ {fold_idx+1} æŠ˜ç‰¹å¾åˆ†å¸ƒ (t-SNE)')
        plt.xlabel('t-SNE ç»´åº¦ 1')
        plt.ylabel('t-SNE ç»´åº¦ 2')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.plots_dir, f'feature_visualization_fold_{fold_idx}.png'),
                   dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_attention_visualization(self, fold_idx, test_loader, model):
        """ç»˜åˆ¶æ³¨æ„åŠ›å¯è§†åŒ–"""
        model.eval()
        
        # è·å–å‡ ä¸ªæ ·æœ¬çš„æ³¨æ„åŠ›æƒé‡
        with torch.no_grad():
            batch = next(iter(test_loader))
            audio_features = batch['audio_features'][:4].to(self.device)  # å–å‰4ä¸ªæ ·æœ¬
            targets = batch['emotion_labels'][:4]
            
            outputs = model(audio_features)
            attention_weights = outputs.get('attention_weights')
            
            if attention_weights is not None:
                attention_weights = attention_weights.cpu().numpy()
                
                fig, axes = plt.subplots(2, 2, figsize=(15, 10))
                axes = axes.flatten()
                
                for i in range(min(4, len(attention_weights))):
                    # å–ç¬¬ä¸€ä¸ªå¤´çš„æ³¨æ„åŠ›æƒé‡
                    attn = attention_weights[i][0]  # [seq_len, seq_len]
                    
                    im = axes[i].imshow(attn, cmap='YlOrRd', aspect='auto')
                    axes[i].set_title(f'æ ·æœ¬ {i+1} - çœŸå®: {self.emotion_labels[targets[i].item()]}')
                    axes[i].set_xlabel('æ—¶é—´æ­¥')
                    axes[i].set_ylabel('æ—¶é—´æ­¥')
                    plt.colorbar(im, ax=axes[i])
                
                plt.suptitle(f'ç¬¬ {fold_idx+1} æŠ˜æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–')
                plt.tight_layout()
                plt.savefig(os.path.join(self.plots_dir, f'attention_weights_fold_{fold_idx}.png'),
                           dpi=300, bbox_inches='tight')
                plt.close()
    
    def run_cross_validation(self):
        """è¿è¡Œå®Œæ•´çš„äº¤å‰éªŒè¯"""
        print("ğŸš€ å¼€å§‹è·¨è¯´è¯äººäº¤å‰éªŒè¯è®­ç»ƒ...")
        
        all_fold_results = []
        
        for fold_idx in range(self.args.n_folds):
            fold_result = self.train_fold(fold_idx)
            all_fold_results.append(fold_result)
            
            # æ›´æ–°æœ€ä½³ç»“æœ
            test_f1 = fold_result['test_results']['f1_score']
            if test_f1 > self.training_history['best_metrics']['f1_score']:
                self.training_history['best_metrics'].update({
                    'accuracy': fold_result['test_results']['accuracy'],
                    'f1_score': test_f1,
                    'fold': fold_idx
                })
        
        # ä¿å­˜æ‰€æœ‰ç»“æœ
        self.training_history['fold_results'] = all_fold_results
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        self.compute_overall_statistics()
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report()
        
        print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
        return self.training_history
    
    def compute_overall_statistics(self):
        """è®¡ç®—æ€»ä½“ç»Ÿè®¡"""
        fold_results = self.training_history['fold_results']
        
        # æå–å„é¡¹æŒ‡æ ‡
        accuracies = [r['test_results']['accuracy'] for r in fold_results]
        f1_scores = [r['test_results']['f1_score'] for r in fold_results]
        precisions = [r['test_results']['precision'] for r in fold_results]
        recalls = [r['test_results']['recall'] for r in fold_results]
        
        # è®¡ç®—ç»Ÿè®¡é‡
        stats = {
            'accuracy': {
                'mean': np.mean(accuracies),
                'std': np.std(accuracies),
                'min': np.min(accuracies),
                'max': np.max(accuracies)
            },
            'f1_score': {
                'mean': np.mean(f1_scores),
                'std': np.std(f1_scores),
                'min': np.min(f1_scores),
                'max': np.max(f1_scores)
            },
            'precision': {
                'mean': np.mean(precisions),
                'std': np.std(precisions),
                'min': np.min(precisions),
                'max': np.max(precisions)
            },
            'recall': {
                'mean': np.mean(recalls),
                'std': np.std(recalls),
                'min': np.min(recalls),
                'max': np.max(recalls)
            }
        }
        
        self.training_history['overall_stats'] = stats
        
        # æ‰“å°ç»“æœ
        print("\\n" + "="*60)
        print("ğŸ“Š è·¨è¯´è¯äººäº¤å‰éªŒè¯æ€»ä½“ç»“æœ")
        print("="*60)
        
        for metric, values in stats.items():
            print(f"{metric.upper():>12}: {values['mean']:.4f} Â± {values['std']:.4f} "
                  f"(min: {values['min']:.4f}, max: {values['max']:.4f})")
        
        print(f"\\nğŸ† æœ€ä½³æ¨¡å‹: ç¬¬ {self.training_history['best_metrics']['fold']+1} æŠ˜")
        print(f"   æœ€ä½³å‡†ç¡®ç‡: {self.training_history['best_metrics']['accuracy']:.4f}")
        print(f"   æœ€ä½³F1åˆ†æ•°: {self.training_history['best_metrics']['f1_score']:.4f}")
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        fold_results = self.training_history['fold_results']
        stats = self.training_history['overall_stats']
        
        # åˆ›å»ºç»¼åˆå›¾è¡¨
        fig = plt.figure(figsize=(20, 15))
        
        # 1. å„foldæ€§èƒ½å¯¹æ¯”
        ax1 = plt.subplot(3, 3, 1)
        fold_indices = range(1, len(fold_results) + 1)
        accuracies = [r['test_results']['accuracy'] for r in fold_results]
        f1_scores = [r['test_results']['f1_score'] for r in fold_results]
        
        x = np.arange(len(fold_indices))
        width = 0.35
        
        ax1.bar(x - width/2, accuracies, width, label='å‡†ç¡®ç‡', alpha=0.8, color='skyblue')
        ax1.bar(x + width/2, f1_scores, width, label='F1åˆ†æ•°', alpha=0.8, color='lightcoral')
        ax1.set_xlabel('Fold')
        ax1.set_ylabel('æ€§èƒ½æŒ‡æ ‡')
        ax1.set_title('å„Foldæ€§èƒ½å¯¹æ¯”')
        ax1.set_xticks(x)
        ax1.set_xticklabels([f'Fold {i}' for i in fold_indices])
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. æ€§èƒ½æŒ‡æ ‡ç®±çº¿å›¾
        ax2 = plt.subplot(3, 3, 2)
        metrics_data = [
            [r['test_results']['accuracy'] for r in fold_results],
            [r['test_results']['f1_score'] for r in fold_results],
            [r['test_results']['precision'] for r in fold_results],
            [r['test_results']['recall'] for r in fold_results]
        ]
        
        ax2.boxplot(metrics_data, labels=['å‡†ç¡®ç‡', 'F1åˆ†æ•°', 'ç²¾ç¡®ç‡', 'å¬å›ç‡'])
        ax2.set_title('æ€§èƒ½æŒ‡æ ‡åˆ†å¸ƒ')
        ax2.set_ylabel('æ•°å€¼')
        ax2.grid(True, alpha=0.3)
        
        # 3. å„æƒ…æ„Ÿç±»åˆ«å¹³å‡æ€§èƒ½
        ax3 = plt.subplot(3, 3, 3)
        # è®¡ç®—å„ç±»åˆ«å¹³å‡F1åˆ†æ•°
        all_f1_per_class = []
        for fold_result in fold_results:
            all_f1_per_class.append(fold_result['test_results']['f1_per_class'])
        
        mean_f1_per_class = np.mean(all_f1_per_class, axis=0)
        std_f1_per_class = np.std(all_f1_per_class, axis=0)
        
        emotion_names = list(self.emotion_labels.values())
        x_pos = np.arange(len(emotion_names))
        
        bars = ax3.bar(x_pos, mean_f1_per_class, yerr=std_f1_per_class, 
                      capsize=5, alpha=0.8, color=self.emotion_colors)
        ax3.set_xlabel('æƒ…æ„Ÿç±»åˆ«')
        ax3.set_ylabel('å¹³å‡F1åˆ†æ•°')
        ax3.set_title('å„æƒ…æ„Ÿç±»åˆ«æ€§èƒ½')
        ax3.set_xticks(x_pos)
        ax3.set_xticklabels(emotion_names)
        ax3.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value, std in zip(bars, mean_f1_per_class, std_f1_per_class):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + std + 0.01,
                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 4-9. å„foldè®­ç»ƒæ›²çº¿ï¼ˆå°å›¾ï¼‰
        for i, fold_result in enumerate(fold_results[:6]):  # æœ€å¤šæ˜¾ç¤º6ä¸ªfold
            ax = plt.subplot(3, 3, i + 4)
            fold_history = fold_result['fold_history']
            epochs = range(1, len(fold_history['train_loss']) + 1)
            
            ax.plot(epochs, fold_history['val_acc'], 'b-', alpha=0.7, label='éªŒè¯å‡†ç¡®ç‡')
            ax.plot(epochs, fold_history['val_f1'], 'r-', alpha=0.7, label='éªŒè¯F1')
            ax.set_title(f'Fold {i+1} è®­ç»ƒæ›²çº¿')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('æ€§èƒ½')
            ax.legend(fontsize=8)
            ax.grid(True, alpha=0.3)
        
        plt.suptitle('è·¨è¯´è¯äººè¯­éŸ³æƒ…æ„Ÿè¯†åˆ« - ç»¼åˆæ€§èƒ½åˆ†ææŠ¥å‘Š', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(os.path.join(self.plots_dir, 'comprehensive_analysis_report.png'),
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_path = os.path.join(self.exp_dir, 'detailed_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.training_history, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="å¢å¼ºçš„IEMOCAPè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«è®­ç»ƒ")
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data_path', type=str, default='./Train_data_org.pickle',
                       help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch_size', type=int, default=16,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_workers', type=int, default=4,
                       help='æ•°æ®åŠ è½½è¿›ç¨‹æ•°')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--hidden_layer', type=int, default=128,
                       help='éšè—å±‚å¤§å°')
    parser.add_argument('--out_class', type=int, default=4,
                       help='è¾“å‡ºç±»åˆ«æ•°')
    parser.add_argument('--dia_layers', type=int, default=2,
                       help='GRUå±‚æ•°')
    parser.add_argument('--dropout', type=float, default=0.3,
                       help='Dropoutæ¯”ä¾‹')
    parser.add_argument('--attention', action='store_true', default=True,
                       help='æ˜¯å¦ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶')
    parser.add_argument('--speaker_norm', action='store_true', default=True,
                       help='æ˜¯å¦ä½¿ç”¨è¯´è¯äººå½’ä¸€åŒ–')
    parser.add_argument('--speaker_adversarial', action='store_true', default=True,
                       help='æ˜¯å¦ä½¿ç”¨è¯´è¯äººå¯¹æŠ—è®­ç»ƒ')
    parser.add_argument('--freeze_layers', type=int, default=6,
                       help='å†»ç»“HuBERTçš„å±‚æ•°')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=50,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=1e-4,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                       help='æƒé‡è¡°å‡')
    parser.add_argument('--max_grad_norm', type=float, default=1.0,
                       help='æ¢¯åº¦è£å‰ªé˜ˆå€¼')
    parser.add_argument('--patience', type=int, default=10,
                       help='æ—©åœpatience')
    parser.add_argument('--T_0', type=int, default=10,
                       help='ä½™å¼¦é€€ç«é‡å¯å‘¨æœŸ')
    
    # å¯¹æŠ—è®­ç»ƒå‚æ•°
    parser.add_argument('--adversarial_weight', type=float, default=0.1,
                       help='å¯¹æŠ—æŸå¤±æƒé‡')
    parser.add_argument('--adversarial_warmup', type=int, default=10,
                       help='å¯¹æŠ—è®­ç»ƒé¢„çƒ­è½®æ•°')
    parser.add_argument('--l2_reg', type=float, default=1e-5,
                       help='L2æ­£åˆ™åŒ–å¼ºåº¦')
    
    # äº¤å‰éªŒè¯å‚æ•°
    parser.add_argument('--n_folds', type=int, default=1,
                       help='äº¤å‰éªŒè¯æŠ˜æ•°')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--cuda', action='store_true', default=True,
                       help='æ˜¯å¦ä½¿ç”¨CUDA')
    parser.add_argument('--log_interval', type=int, default=50,
                       help='æ—¥å¿—æ‰“å°é—´éš”')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    
    return parser.parse_args()

def set_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºçš„IEMOCAPè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«è®­ç»ƒç³»ç»Ÿ")
    print("="*60)
    
    # è§£æå‚æ•°
    args = parse_args()
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    # æ‰“å°é…ç½®
    print("ğŸ“‹ è®­ç»ƒé…ç½®:")
    for key, value in vars(args).items():
        print(f"   {key}: {value}")
    print("="*60)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = AdvancedTrainer(args)
    
    # è¿è¡Œè®­ç»ƒ
    try:
        results = trainer.run_cross_validation()
        
        print("\\nğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆ!")
        print(f"ğŸ“ å®éªŒç»“æœä¿å­˜åœ¨: {trainer.exp_dir}")
        print(f"ğŸ† æœ€ä½³æ€§èƒ½: å‡†ç¡®ç‡ {results['best_metrics']['accuracy']:.4f}, "
              f"F1åˆ†æ•° {results['best_metrics']['f1_score']:.4f}")
        
        return results
        
    except KeyboardInterrupt:
        print("\\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()
