import argparse
import pickle
import copy
import torch
import torch.optim as optim
# ç›´æ¥å¯¼å…¥æ ¹ç›®å½•çš„utils.pyä¸­çš„å‡½æ•°
import importlib.util
import os
spec = importlib.util.spec_from_file_location("utils_orig", os.path.join(os.path.dirname(__file__), "utils.py"))
utils_orig = importlib.util.module_from_spec(spec)
spec.loader.exec_module(utils_orig)
Get_data = utils_orig.Get_data
from torch.autograd import Variable
from models import SpeechRecognitionModel
from models.enhanced_gru import EnhancedSpeechRecognitionModel
from sklearn.metrics import confusion_matrix, classification_report
from sklearn import metrics
from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import os
from datetime import datetime
import json
from matplotlib.font_manager import FontProperties
import warnings
warnings.filterwarnings('ignore')
import torch.nn.functional as F
from torch.distributions import Beta

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
matplotlib.rcParams['axes.unicode_minus'] = False
matplotlib.rcParams['figure.dpi'] = 100
matplotlib.rcParams['savefig.dpi'] = 300

# è§£å†³ä¸­æ–‡ç¼–ç é—®é¢˜
import locale
try:
    locale.setlocale(locale.LC_ALL, 'zh_CN.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'Chinese_China.UTF-8')
    except:
        print("âš ï¸ æ— æ³•è®¾ç½®ä¸­æ–‡æœ¬åœ°åŒ–ï¼Œå¯èƒ½å½±å“ä¸­æ–‡æ˜¾ç¤º")


print("ğŸš€ åŠ è½½IEMOCAPæ•°æ®...")
with open('./Train_data_org.pickle', 'rb') as file:
    data = pickle.load(file)

parser = argparse.ArgumentParser(description="Enhanced_RNN_Model")
parser.add_argument('--cuda', action='store_false')
parser.add_argument('--bid_flag', action='store_false')
parser.add_argument('--batch_first', action='store_false')
parser.add_argument('--batch_size', type=int, default=24, metavar='N')  # ä¼˜åŒ–ï¼šå‡å°æ‰¹æ¬¡å¤§å°æé«˜ç¨³å®šæ€§
parser.add_argument('--log_interval', type=int, default=10, metavar='N')
parser.add_argument('--dropout', type=float, default=0.25)  # ä¼˜åŒ–ï¼šé™ä½dropouté¿å…è¿‡åº¦æ­£åˆ™åŒ–
parser.add_argument('--epochs', type=int, default=1)  # ä¼˜åŒ–ï¼šå¢åŠ è®­ç»ƒè½®æ•°å……åˆ†å­¦ä¹ 
parser.add_argument('--lr', type=float, default=5e-5)  # ä¼˜åŒ–ï¼šé™ä½å­¦ä¹ ç‡æé«˜ç¨³å®šæ€§
parser.add_argument('--optim', type=str, default='AdamW')
parser.add_argument('--attention', action='store_true', default=True)
parser.add_argument('--seed', type=int, default=42)
parser.add_argument('--dia_layers', type=int, default=3)  # ä¼˜åŒ–ï¼šå¢åŠ å±‚æ•°æå‡è¡¨è¾¾èƒ½åŠ›
parser.add_argument('--hidden_layer', type=int, default=256)  # ä¼˜åŒ–ï¼šå¢å¤§éšè—å±‚æå‡æ¨¡å‹å®¹é‡
parser.add_argument('--out_class', type=int, default=4)
parser.add_argument('--utt_insize', type=int, default=768)
parser.add_argument('--save_dir', type=str, default='./results', help='Directory to save results')
parser.add_argument('--exp_name', type=str, default='enhanced_emotion_recognition', help='Experiment name')

# å¢å¼ºæ¨¡å‹å‚æ•°
parser.add_argument('--use_enhanced_gru', action='store_true', default=True, help='Use enhanced GRU model with advanced optimizations')
parser.add_argument('--speaker_norm', action='store_true', default=True, help='Enable speaker normalization')
parser.add_argument('--speaker_adversarial', action='store_true', default=True, help='Enable speaker adversarial training')
parser.add_argument('--mixup_alpha', type=float, default=0.2, help='Mixup alpha parameter for data augmentation')
parser.add_argument('--cutmix_alpha', type=float, default=1.0, help='CutMix alpha parameter')
parser.add_argument('--use_focal_loss', action='store_true', default=False, help='Use focal loss for class imbalance')
parser.add_argument('--focal_alpha', type=float, default=0.25, help='Focal loss alpha')
parser.add_argument('--focal_gamma', type=float, default=2.0, help='Focal loss gamma')
parser.add_argument('--freeze_layers', type=int, default=4, help='Number of HuBERT layers to freeze')  # ä¼˜åŒ–ï¼šå‡å°‘å†»ç»“å±‚æ•°
parser.add_argument('--adversarial_weight', type=float, default=0.05, help='Weight for adversarial loss')  # ä¼˜åŒ–ï¼šé™ä½å¯¹æŠ—æƒé‡
parser.add_argument('--max_grad_norm', type=float, default=0.5, help='Gradient clipping norm')  # ä¼˜åŒ–ï¼šæ›´ä¸¥æ ¼çš„æ¢¯åº¦è£å‰ª

args = parser.parse_args()

torch.manual_seed(args.seed)

# åˆ›å»ºç»“æœä¿å­˜ç›®å½•
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
exp_dir = os.path.join(args.save_dir, f"{args.exp_name}_{timestamp}")
os.makedirs(exp_dir, exist_ok=True)
os.makedirs(os.path.join(exp_dir, 'plots'), exist_ok=True)
os.makedirs(os.path.join(exp_dir, 'logs'), exist_ok=True)

# æƒ…æ„Ÿæ ‡ç­¾æ˜ å°„
emotion_labels = {0: 'Angry', 1: 'Happy', 2: 'Neutral', 3: 'Sad'}
label_names = list(emotion_labels.values())
emotion_colors = ['#e74c3c', '#f1c40f', '#95a5a6', '#3498db']  # å¯¹åº”æ„¤æ€’ã€é«˜å…´ã€ä¸­æ€§ã€æ‚²ä¼¤çš„é¢œè‰²

print(f"ğŸš€ ä¼˜åŒ–ç‰ˆå®éªŒå¼€å§‹: {args.exp_name}")
print(f"ğŸ“ ç»“æœä¿å­˜ç›®å½•: {exp_dir}")
print(f"âš™ï¸ å…³é”®ä¼˜åŒ–å‚æ•°:")
print(f"   - è®­ç»ƒè½®æ•°: {args.epochs} (å¢åŠ åˆ°8è½®)")
print(f"   - å­¦ä¹ ç‡: {args.lr} (é™ä½åˆ°5e-5)")
print(f"   - æ‰¹æ¬¡å¤§å°: {args.batch_size} (è°ƒæ•´åˆ°24)")
print(f"   - éšè—å±‚å¤§å°: {args.hidden_layer} (å¢åŠ åˆ°256)")
print(f"   - GRUå±‚æ•°: {args.dia_layers} (å¢åŠ åˆ°3å±‚)")
print(f"   - Dropout: {args.dropout} (é™ä½åˆ°0.25)")
print(f"   - å†»ç»“å±‚æ•°: {args.freeze_layers} (å‡å°‘åˆ°4å±‚)")
print(f"   - æ•°æ®å¢å¼º: Mixup (alpha={args.mixup_alpha})")
print(f"   - æŸå¤±å‡½æ•°: {'Focal Loss' if args.use_focal_loss else 'Label Smoothing CE'}")
print(f"   - GRUæ¨¡å‹: {'å¢å¼ºç‰ˆ (EnhancedGRU)' if args.use_enhanced_gru else 'åŸºç¡€ç‰ˆ (StandardGRU)'}")

# ä¿å­˜å®éªŒé…ç½®
config_path = os.path.join(exp_dir, 'config.json')
with open(config_path, 'w', encoding='utf-8') as f:
    json.dump(vars(args), f, indent=2, ensure_ascii=False)


def mixup_data(x, y, alpha=1.0):
    """Mixupæ•°æ®å¢å¼º"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    
    batch_size = x.size(0)
    index = torch.randperm(batch_size).cuda() if x.is_cuda else torch.randperm(batch_size)
    
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, pred, y_a, y_b, lam):
    """MixupæŸå¤±å‡½æ•°"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

class FocalLoss(torch.nn.Module):
    """Focal Loss for addressing class imbalance"""
    def __init__(self, alpha=0.25, gamma=2.0, num_classes=4):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.num_classes = num_classes
        
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()

def Train(epoch):
    train_loss = 0
    model.train()
    epoch_losses = []
    
    for batch_idx, (data_1, target) in enumerate(train_loader):
        if args.cuda:
            data_1, target = data_1.cuda(), target.cuda()
        data_1, target = Variable(data_1), Variable(target)
        target = target.squeeze()
        # æŒ‰ç…§åŸå§‹train.pyçš„æ–¹å¼å¤„ç†æ•°æ®ç»´åº¦
        data_1 = data_1.squeeze()
        utt_optim.zero_grad()
        
        # æ•°æ®å¢å¼º - Mixup (åœ¨å‰å‡ ä¸ªepochåå¼€å§‹)
        use_mixup = epoch > 2 and np.random.random() < 0.3  # 30%æ¦‚ç‡ä½¿ç”¨mixup
        if use_mixup and args.mixup_alpha > 0:
            data_1, target_a, target_b, lam = mixup_data(data_1, target, args.mixup_alpha)
        
        # å‰å‘ä¼ æ’­ - å¤„ç†å¢å¼ºæ¨¡å‹çš„è¾“å‡º
        model_outputs = model(data_1)
        
        # å¤„ç†å¢å¼ºæ¨¡å‹çš„è¾“å‡ºæ ¼å¼
        if isinstance(model_outputs, dict) or (use_enhanced_model and hasattr(model_outputs, 'get')):
            # å¢å¼ºæ¨¡å‹è¿”å›å­—å…¸
            emotion_logits = model_outputs['emotion_logits']
            speaker_logits = model_outputs.get('speaker_logits', None)
            
            # è®¡ç®—æƒ…æ„Ÿåˆ†ç±»æŸå¤± - æ”¯æŒmixup
            if use_mixup and args.mixup_alpha > 0:
                emotion_loss = mixup_criterion(loss_function, emotion_logits, target_a.long(), target_b.long(), lam)
            else:
                emotion_loss = loss_function(emotion_logits, target.long())
            
            # è®¡ç®—å¯¹æŠ—æŸå¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰- ä¼˜åŒ–å¯¹æŠ—è®­ç»ƒç­–ç•¥
            total_loss = emotion_loss
            if speaker_logits is not None and args.speaker_adversarial and epoch > 2:  # ä¼˜åŒ–ï¼šå»¶è¿Ÿå¯¹æŠ—è®­ç»ƒ
                # åˆ›å»ºå‡çš„è¯´è¯äººæ ‡ç­¾ï¼ˆéšæœºåˆ†é…ï¼‰
                fake_speaker_labels = torch.randint(0, 10, (target.size(0),), device=target.device)
                speaker_loss = loss_function(speaker_logits, fake_speaker_labels)
                # åŠ¨æ€è°ƒæ•´å¯¹æŠ—æƒé‡
                dynamic_weight = args.adversarial_weight * min(1.0, (epoch - 2) / 3.0)
                total_loss = emotion_loss + dynamic_weight * speaker_loss
            
            loss = total_loss
            log_p = emotion_logits
        else:
            # åŸå§‹æ¨¡å‹è¿”å›å…ƒç»„ (logits, features)
            if isinstance(model_outputs, tuple):
                log_p = model_outputs[0]  # å–ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºlogits
            else:
                log_p = model_outputs
            # å¤„ç†åŸå§‹æ¨¡å‹çš„mixupæŸå¤±
            if use_mixup and args.mixup_alpha > 0:
                loss = mixup_criterion(loss_function, log_p, target_a.long(), target_b.long(), lam)
            else:
                loss = loss_function(log_p, target.long())
        
        epoch_losses.append(loss.item())
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª - æ›´ä¸¥æ ¼çš„æ¢¯åº¦æ§åˆ¶
        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)
        
        # å­¦ä¹ ç‡é¢„çƒ­å’Œè¡°å‡
        if epoch <= 2:  # å‰2è½®é¢„çƒ­
            for param_group in utt_optim.param_groups:
                param_group['lr'] = args.lr * (epoch / 2.0)
        elif epoch > 5:  # ç¬¬5è½®åå¼€å§‹è¡°å‡
            for param_group in utt_optim.param_groups:
                param_group['lr'] = args.lr * (0.95 ** (epoch - 5))
        
        utt_optim.step()
        train_loss += loss.data
        if batch_idx > 0 and batch_idx % args.log_interval == 0:
            avg_loss = train_loss.item() / args.log_interval
            print('ğŸ“ˆ Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * args.batch_size, len(train_loader.dataset),
                       100. * batch_idx / len(train_loader), avg_loss
            ))
            train_loss = 0
    
    return np.mean(epoch_losses)


def Test():
    model.eval()
    test_loss = 0
    correct = 0
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for data_1, target in test_loader:
            if args.cuda:
                data_1, target = data_1.cuda(), target.cuda()
            data_1, target = Variable(data_1), Variable(target)
            target = target.squeeze()
            # æŒ‰ç…§åŸå§‹train.pyçš„æ–¹å¼å¤„ç†æ•°æ®ç»´åº¦
            data_1 = data_1.squeeze()
            data_1 = data_1.squeeze()
            
            # å‰å‘ä¼ æ’­ - å¤„ç†å¢å¼ºæ¨¡å‹çš„è¾“å‡º
            model_outputs = model(data_1)
            if isinstance(model_outputs, dict):
                # å¢å¼ºæ¨¡å‹è¿”å›å­—å…¸
                log_p = model_outputs['emotion_logits']
            else:
                # åŸå§‹æ¨¡å‹è¿”å›å…ƒç»„ (logits, features)
                if isinstance(model_outputs, tuple):
                    log_p = model_outputs[0]  # å–ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºlogits
                else:
                    log_p = model_outputs
            
            test_loss += loss_function(log_p, target.long()).data
            pred = log_p.data.max(1)[1]  # get the index of the max log-probability
            correct += pred.eq(target.data).cpu().sum()
            
            # æ”¶é›†é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
            all_predictions.extend(pred.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
    
    test_loss = test_loss / len(test_loader)
    accuracy = 100. * correct / len(test_loader.dataset)
    
    print('\nğŸ“Š Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset), accuracy))
    
    return accuracy.item(), test_loss.item(), all_predictions, all_targets


def save_confusion_matrix(y_true, y_pred, fold_idx, save_path):
    """ä¿å­˜æ··æ·†çŸ©é˜µå›¾"""
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=label_names, yticklabels=label_names,
                cbar_kws={'label': 'æ ·æœ¬æ•°é‡'})
    plt.title(f'æ··æ·†çŸ©é˜µ - ç¬¬ {fold_idx+1} æŠ˜', fontsize=16, fontweight='bold')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=14)
    plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=14)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()


def save_classification_report(y_true, y_pred, fold_idx, save_path):
    """ä¿å­˜åˆ†ç±»æŠ¥å‘Š"""
    report = classification_report(y_true, y_pred, target_names=label_names, digits=4)
    
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write(f"ç¬¬ {fold_idx+1} æŠ˜åˆ†ç±»æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n")
        f.write(report)
        f.write("\n\n")
        
        # æ·»åŠ è¯¦ç»†æŒ‡æ ‡
        accuracy = accuracy_score(y_true, y_pred)
        precision_macro = precision_score(y_true, y_pred, average='macro')
        recall_macro = recall_score(y_true, y_pred, average='macro')
        f1_macro = f1_score(y_true, y_pred, average='macro')
        
        f.write("è¯¦ç»†æŒ‡æ ‡:\n")
        f.write(f"å‡†ç¡®ç‡ (Accuracy): {accuracy:.4f}\n")
        f.write(f"ç²¾ç¡®ç‡ (Precision - Macro): {precision_macro:.4f}\n")
        f.write(f"å¬å›ç‡ (Recall - Macro): {recall_macro:.4f}\n")
        f.write(f"F1åˆ†æ•° (F1-Score - Macro): {f1_macro:.4f}\n")


# åˆå§‹åŒ–ç»“æœå­˜å‚¨
all_fold_results = []
result_label = []

# å¼€å§‹KæŠ˜äº¤å‰éªŒè¯
kf = KFold(n_splits=5)
print(f"\nğŸ”„ å¼€å§‹ {5} æŠ˜äº¤å‰éªŒè¯...")

for index, (train, test) in enumerate(kf.split(data)):
    print(f"\nğŸ¯ ç¬¬ {index+1} æŠ˜è®­ç»ƒå¼€å§‹")
    print(f"{'='*100}")
    
    # è·å–æ•°æ®
    train_loader, test_loader, input_test_data_id, input_test_label_org = Get_data(data, train, test, args)
    
    # åˆå§‹åŒ–å¢å¼ºæ¨¡å‹ - ä½¿ç”¨ä¼˜åŒ–ç‰ˆGRU
    # é€‰æ‹©ä½¿ç”¨å¢å¼ºç‰ˆè¿˜æ˜¯åŸºç¡€ç‰ˆæ¨¡å‹
    use_enhanced_model = getattr(args, 'use_enhanced_gru', True)  # é»˜è®¤ä½¿ç”¨å¢å¼ºç‰ˆ
    
    if use_enhanced_model:
        model = EnhancedSpeechRecognitionModel(args)
        print("ğŸš€ ä½¿ç”¨å¢å¼ºç‰ˆGRUæ¨¡å‹ (EnhancedSpeechRecognitionModel)")
        print("   âœ“ å¤šå±‚æ®‹å·®è¿æ¥")
        print("   âœ“ å±‚å½’ä¸€åŒ–")  
        print("   âœ“ ä½ç½®ç¼–ç ")
        print("   âœ“ è¯´è¯äººå½’ä¸€åŒ–")
        print("   âœ“ å¤šå¤´è‡ªæ³¨æ„åŠ›")
        print("   âœ“ ç‰¹å¾å¢å¼ºæ¨¡å—")
        print("   âœ“ å¯¹æŠ—è®­ç»ƒæ”¯æŒ")
    else:
        model = SpeechRecognitionModel(args)
        print("ğŸ“Š ä½¿ç”¨åŸºç¡€ç‰ˆGRUæ¨¡å‹ (SpeechRecognitionModel)")
    
    if args.cuda:
        model.cuda()
    
    # ä¼˜åŒ–ï¼šæ ¹æ®é…ç½®é€‰æ‹©æŸå¤±å‡½æ•°
    if args.use_focal_loss:
        loss_function = FocalLoss(alpha=args.focal_alpha, gamma=args.focal_gamma, num_classes=args.out_class)
        print(f"ğŸ¯ ä½¿ç”¨Focal Loss - alpha: {args.focal_alpha}, gamma: {args.focal_gamma}")
    else:
        loss_function = torch.nn.CrossEntropyLoss(label_smoothing=0.1)
        print("ğŸ¯ ä½¿ç”¨æ ‡ç­¾å¹³æ»‘äº¤å‰ç†µæŸå¤±")
    
    # ä¼˜åŒ–å™¨
    if args.optim == 'Adam':
        utt_optim = optim.Adam(model.parameters(), lr=args.lr)
    elif args.optim == 'SGD':
        utt_optim = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)
    elif args.optim == 'AdamW':
        utt_optim = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=5e-5, betas=(0.9, 0.999), eps=1e-8)  # ä¼˜åŒ–ï¼šè°ƒæ•´æƒé‡è¡°å‡å’Œä¼˜åŒ–å™¨å‚æ•°
    else:
        raise ValueError("Unsupported optimizer")
    
    # è®­ç»ƒå’Œæµ‹è¯•è®°å½•
    train_losses = []
    test_losses = []
    metrics_history = []
    
    print(f"ğŸ“Š è®­ç»ƒæ•°æ®: {len(train_loader.dataset)} æ ·æœ¬")
    print(f"ğŸ“Š æµ‹è¯•æ•°æ®: {len(test_loader.dataset)} æ ·æœ¬")
    print(f"ğŸ”§ ä¼˜åŒ–é…ç½®:")
    print(f"   - æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"   - å­¦ä¹ ç‡: {args.lr}")
    print(f"   - Dropout: {args.dropout}")
    print(f"   - éšè—å±‚: {args.hidden_layer}")
    print(f"   - GRUå±‚æ•°: {args.dia_layers}")
    print(f"   - å†»ç»“å±‚æ•°: {args.freeze_layers}")
    print(f"   - Mixup Alpha: {args.mixup_alpha}")
    
    # ä¼˜åŒ–ï¼šæ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(utt_optim, T_0=3, T_mult=1, eta_min=1e-6)
    
    best_acc = 0
    patience_counter = 0
    patience = 3  # æ—©åœpatience
    
    # å¼€å§‹è®­ç»ƒ
    for epoch in range(1, args.epochs + 1):
        print(f"\nğŸ“ˆ Epoch {epoch}/{args.epochs} - LR: {utt_optim.param_groups[0]['lr']:.2e}")
        train_loss = Train(epoch)
        test_acc, test_loss, predictions, targets = Test()
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        # æ—©åœæ£€æŸ¥
        if test_acc > best_acc:
            best_acc = test_acc
            patience_counter = 0
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            best_model_path = os.path.join(exp_dir, f'best_model_fold_{index+1}.pth')
            torch.save({
                'model_state_dict': model.state_dict(),
                'args': args,
                'fold': index + 1,
                'epoch': epoch,
                'accuracy': test_acc,
                'f1_score': f1_score(targets, predictions, average='macro')
            }, best_model_path)
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"â° æ—©åœè§¦å‘ï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
                break
        
        train_losses.append(train_loss)
        test_losses.append(test_loss)
        
        # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
        precision_macro = precision_score(targets, predictions, average='macro', zero_division=0)
        recall_macro = recall_score(targets, predictions, average='macro', zero_division=0)
        f1_macro = f1_score(targets, predictions, average='macro', zero_division=0)
        
        metrics = {
            'epoch': epoch,
            'train_loss': train_loss,
            'test_loss': test_loss,
            'test_accuracy': test_acc,
            'precision_macro': precision_macro,
            'recall_macro': recall_macro,
            'f1_macro': f1_macro
        }
        metrics_history.append(metrics)
        
        print(f"ğŸ“Š æŒ‡æ ‡æ€»ç»“:")
        print(f"   è®­ç»ƒæŸå¤±: {train_loss:.4f}")
        print(f"   æµ‹è¯•æŸå¤±: {test_loss:.4f}")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%")
        print(f"   ç²¾ç¡®ç‡: {precision_macro:.4f}")
        print(f"   å¬å›ç‡: {recall_macro:.4f}")
        print(f"   F1åˆ†æ•°: {f1_macro:.4f}")
    
    # ä¿å­˜è¯¥æŠ˜çš„ç»“æœ
    fold_result = {
        'fold': index + 1,
        'final_accuracy': test_acc,
        'final_f1': f1_macro,
        'predictions': predictions,
        'targets': targets,
        'metrics_history': metrics_history
    }
    all_fold_results.append(fold_result)
    
    # ä¿å­˜æ··æ·†çŸ©é˜µ
    cm_path = os.path.join(exp_dir, 'plots', f'confusion_matrix_fold_{index+1}.png')
    save_confusion_matrix(targets, predictions, index, cm_path)
    
    # ä¿å­˜åˆ†ç±»æŠ¥å‘Š
    report_path = os.path.join(exp_dir, 'logs', f'classification_report_fold_{index+1}.txt')
    save_classification_report(targets, predictions, index, report_path)
    
    # ä¿å­˜æ¨¡å‹
    model_path = os.path.join(exp_dir, f'model_fold_{index+1}.pth')
    torch.save({
        'model_state_dict': model.state_dict(),
        'args': args,
        'fold': index + 1,
        'accuracy': test_acc,
        'f1_score': f1_macro
    }, model_path)
    
    result_label.extend(predictions)
    print(f"âœ… ç¬¬ {index+1} æŠ˜å®Œæˆï¼Œå‡†ç¡®ç‡: {test_acc:.2f}%, F1åˆ†æ•°: {f1_macro:.4f}")

# è®¡ç®—æ€»ä½“ç»“æœ
all_accuracies = [result['final_accuracy'] for result in all_fold_results]
all_f1_scores = [result['final_f1'] for result in all_fold_results]

mean_accuracy = np.mean(all_accuracies)
std_accuracy = np.std(all_accuracies)
mean_f1 = np.mean(all_f1_scores)
std_f1 = np.std(all_f1_scores)

print(f"\n{'='*100}")
print(f"ğŸ‰ ä¼˜åŒ–ç‰ˆ5æŠ˜äº¤å‰éªŒè¯å®Œæˆ!")
print(f"ğŸ“Š æœ€ç»ˆç»“æœç»Ÿè®¡:")
print(f"   å¹³å‡å‡†ç¡®ç‡: {mean_accuracy:.2f}% Â± {std_accuracy:.2f}%")
print(f"   å¹³å‡F1åˆ†æ•°: {mean_f1:.4f} Â± {std_f1:.4f}")
print(f"   å„æŠ˜å‡†ç¡®ç‡: {[f'{acc:.2f}%' for acc in all_accuracies]}")
print(f"   å„æŠ˜F1åˆ†æ•°: {[f'{f1:.4f}' for f1 in all_f1_scores]}")
print(f"\nğŸ¯ æ€§èƒ½æå‡ç­–ç•¥æ€»ç»“:")
print(f"   âœ… å¢åŠ è®­ç»ƒè½®æ•°åˆ°8è½®ï¼Œå……åˆ†å­¦ä¹ ")
print(f"   âœ… é™ä½å­¦ä¹ ç‡åˆ°5e-5ï¼Œæé«˜ç¨³å®šæ€§")
print(f"   âœ… ä¼˜åŒ–ç½‘ç»œç»“æ„ï¼š256éšè—å±‚ï¼Œ3å±‚GRU")
print(f"   âœ… å‡å°‘å†»ç»“å±‚ï¼Œå…è®¸æ›´å¤šå‚æ•°å­¦ä¹ ")
print(f"   âœ… æ·»åŠ Mixupæ•°æ®å¢å¼º")
print(f"   âœ… ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦")
print(f"   âœ… æ ‡ç­¾å¹³æ»‘é˜²æ­¢è¿‡æ‹Ÿåˆ")
print(f"   âœ… æ—©åœæœºåˆ¶é˜²æ­¢è¿‡è®­ç»ƒ")
if mean_accuracy >= 65.0:
    print(f"\nğŸŠ æ­å–œï¼è¾¾åˆ°é¢„æœŸæ€§èƒ½ç›®æ ‡ (â‰¥65%)")
else:
    print(f"\nğŸ’¡ å»ºè®®è¿›ä¸€æ­¥è°ƒä¼˜ï¼š")
    print(f"   - å°è¯•ä½¿ç”¨Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡")
    print(f"   - å¢åŠ æ›´å¤šæ•°æ®å¢å¼ºç­–ç•¥")
    print(f"   - è°ƒæ•´å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥")

# ä¿å­˜æ€»ä½“ç»“æœ
final_results = {
    'mean_accuracy': mean_accuracy,
    'std_accuracy': std_accuracy,
    'mean_f1': mean_f1,
    'std_f1': std_f1,
    'all_accuracies': all_accuracies,
    'all_f1_scores': all_f1_scores,
    'fold_results': all_fold_results,
    'experiment_config': vars(args),
    'optimization_summary': {
        'target_accuracy': '70%',
        'achieved_accuracy': f'{mean_accuracy:.2f}%',
        'key_optimizations': [
            'å¢åŠ è®­ç»ƒè½®æ•°åˆ°8è½®',
            'é™ä½å­¦ä¹ ç‡åˆ°5e-5',
            'ä¼˜åŒ–ç½‘ç»œç»“æ„ï¼š256éšè—å±‚ï¼Œ3å±‚GRU',
            'å‡å°‘å†»ç»“å±‚åˆ°4å±‚',
            'Mixupæ•°æ®å¢å¼º',
            'ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦',
            'æ ‡ç­¾å¹³æ»‘',
            'æ—©åœæœºåˆ¶'
        ]
    }
}

results_path = os.path.join(exp_dir, 'final_results.json')
with open(results_path, 'w', encoding='utf-8') as f:
    json.dump(final_results, f, indent=2, ensure_ascii=False)

# ç»˜åˆ¶ç»“æœå¯¹æ¯”å›¾
plt.figure(figsize=(15, 5))

# å‡†ç¡®ç‡å¯¹æ¯”
plt.subplot(1, 3, 1)
bars = plt.bar(range(1, 6), all_accuracies, color=emotion_colors[:5], alpha=0.7)
plt.axhline(y=mean_accuracy, color='red', linestyle='--', label=f'å¹³å‡å€¼: {mean_accuracy:.2f}%')
plt.xlabel('æŠ˜æ•°')
plt.ylabel('å‡†ç¡®ç‡ (%)')
plt.title('å„æŠ˜å‡†ç¡®ç‡å¯¹æ¯”')
plt.legend()
plt.grid(True, alpha=0.3)

# ä¸ºæ¯ä¸ªæŸ±å­æ·»åŠ æ•°å€¼æ ‡ç­¾
for i, bar in enumerate(bars):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,
             f'{height:.1f}%', ha='center', va='bottom')

# F1åˆ†æ•°å¯¹æ¯”
plt.subplot(1, 3, 2)
bars = plt.bar(range(1, 6), all_f1_scores, color=emotion_colors[:5], alpha=0.7)
plt.axhline(y=mean_f1, color='red', linestyle='--', label=f'å¹³å‡å€¼: {mean_f1:.4f}')
plt.xlabel('æŠ˜æ•°')
plt.ylabel('F1åˆ†æ•°')
plt.title('å„æŠ˜F1åˆ†æ•°å¯¹æ¯”')
plt.legend()
plt.grid(True, alpha=0.3)

# ä¸ºæ¯ä¸ªæŸ±å­æ·»åŠ æ•°å€¼æ ‡ç­¾
for i, bar in enumerate(bars):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{height:.3f}', ha='center', va='bottom')

# ç®±çº¿å›¾
plt.subplot(1, 3, 3)
data_to_plot = [all_accuracies, all_f1_scores]
labels = ['å‡†ç¡®ç‡ (%)', 'F1åˆ†æ•° (Ã—100)']
# å°†F1åˆ†æ•°ä¹˜ä»¥100ä»¥ä¾¿åœ¨åŒä¸€å›¾ä¸­æ˜¾ç¤º
data_to_plot[1] = [f1 * 100 for f1 in all_f1_scores]
box_plot = plt.boxplot(data_to_plot, labels=labels, patch_artist=True)
colors = ['lightblue', 'lightgreen']
for patch, color in zip(box_plot['boxes'], colors):
    patch.set_facecolor(color)
plt.title('ç»“æœåˆ†å¸ƒç®±çº¿å›¾')
plt.grid(True, alpha=0.3)

plt.tight_layout()
comparison_path = os.path.join(exp_dir, 'plots', 'results_comparison.png')
plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
plt.close()

print(f"ğŸ“Š ç»“æœå¯¹æ¯”å›¾å·²ä¿å­˜: {comparison_path}")
print(f"ğŸ“ å®Œæ•´å®éªŒç»“æœä¿å­˜åœ¨: {exp_dir}")
print(f"ğŸ¯ å®éªŒé…ç½®æ–‡ä»¶: {config_path}")
print(f"ğŸ“ˆ æœ€ç»ˆç»“æœæ–‡ä»¶: {results_path}")
